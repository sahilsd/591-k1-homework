{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(In order to load the stylesheet of this notebook, execute the last code cell in this notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Hotel Ratings on Tripadvisor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework we will focus on practicing two techniques: web scraping and regression. For the first part, we will get some basic information for each hotel in Boston. Then, we will fit a regression model on this information and try to analyze it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Task 1 (30 pts)**\n",
    "\n",
    "We will scrape the data using Beautiful Soup. For each hotel that our search returns, we will get the information below.\n",
    "\n",
    "![Information to be scraped](hotel_info.png)\n",
    "\n",
    "Of course, feel free to collect even more data if you want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " get url\n",
      "URL TO REQUEST: http://www.tripadvisor.com/TypeAheadJson?query=boston%20massachusetts&action=API\n",
      "RESULTS:  {u'lookbackServlet': None, u'name': u'Boston, Massachusetts, United States', u'data_type': u'LOCATION', u'title': u'Destinations', u'url': u'/Tourism-g60745-Boston_Massachusetts-Vacations.html', u'value': 60745, u'coords': u'42.357277,-71.05834', u'urls': [{u'url': u'/Tourism-g60745-Boston_Massachusetts-Vacations.html', u'type': u'GEO', u'name': u'Boston Tourism', u'url_type': u'geo'}], u'scope': u'global', u'type': u'GEO'}\n",
      "CITY PAGE URL: /Hotels-g60745-Boston_Massachusetts-Hotels.html\n",
      "Hotel page 1\n",
      "30 hotels\n",
      "Omni Parker House . Found Omni Parker House. Scrape reviews\n",
      "HOTEL NAME: Omni Parker House\n",
      "HOTEL REVIEWS:  5,620 Reviews\n",
      "HOTEL STAR RATING: 4\n",
      "Done scraping omni hotel\n",
      "Hyatt Regency Boston Harbor . Seaport Boston Hotel . Hotel Commonwealth . Revere Hotel Boston Common . The Westin Copley Place . Sheraton Boston Hotel . InterContinental Boston . Nine Zero Hotel - a Kimpton Hotel . Boston Harbor Hotel . Boston Marriott Copley Place . Lenox Hotel . Fairmont Copley Plaza, Boston . Courtyard by Marriott Boston Copley Square . enVision Hotel Boston . The Midtown Hotel . The Liberty Hotel . Boston Hotel Buckminster . The Langham, Boston . Embassy Suites by Hilton Boston - at Logan Airport . Harborside Inn . DoubleTree Club by Hilton Hotel Boston Bayside . XV Beacon . Boston Marriott Long Wharf . Hilton Boston Downtown / Faneuil Hall . Holiday Inn Express Boston . W Boston . Loews Boston Hotel . Taj Boston . The Verb Hotel . Next url is /Hotels-g60745-oa30-Boston_Massachusetts-Hotels.html#ACCOM_OVERVIEW\n",
      "Hotel page 2\n",
      "30 hotels\n",
      "The Bostonian Boston . Residence Inn Boston Back Bay / Fenway . Hilton Boston Back Bay . Hilton Boston Logan Airport . The Boxer Boston . Hyatt Regency Boston . Chandler Inn . The Westin Boston Waterfront . Copley House . Hampton Inn &amp; Suites Boston Crosstown Center . Marriott&#39;s Custom House . Colonnade Hotel . Copley Square Hotel . DoubleTree Suites by Hilton Boston-Cambridge . DoubleTree by Hilton Hotel Boston - Downtown . Residence Inn by Marriott Boston Harbor on Tudor Wharf . Eliot Hotel . Club Quarters Hotel in Boston . Four Seasons Hotel Boston . Wyndham Boston Beacon Hill . Battery Wharf Hotel, Boston Waterfront . Newbury Guest House . Charlesmark Hotel . Courtyard by Marriott Boston Logan Airport . Mandarin Oriental, Boston . Onyx Hotel - a Kimpton Hotel . BEST WESTERN PLUS Roundhouse Suites . The Inn At St Botolph . Renaissance Boston Waterfront Hotel . Hotel 140 . Next url is /Hotels-g60745-oa60-Boston_Massachusetts-Hotels.html#ACCOM_OVERVIEW\n",
      "Hotel page 3\n",
      "22 hotels\n",
      "Holiday Inn Express Hotel &amp; Suites Boston Garden . Residence Inn Boston Downtown Seaport . The Ritz-Carlton, Boston . The Inn at Longwood Medical . Ames Boston Hotel . Courtyard Boston-South Boston . BEST WESTERN University Hotel Boston-Brighton . Beacon Hill Hotel and Bistro . Hilton Garden Inn Boston Logan Airport . The Godfrey Hotel Boston . The Envoy Hotel, Autograph Collection . Courtyard Boston Downtown . Comfort Inn - Boston . Aloft Boston Seaport . Boston Park Plaza . Element Boston Seaport . The Boston Common Hotel and Conference Center . Milner Hotel . Constitution Inn . Ramada Boston . Days Hotel Boston . Americas Best Value Inn . \n",
      "Reached last page\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from BeautifulSoup import BeautifulSoup\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "import requests\n",
    "import codecs\n",
    "import json\n",
    "import collections\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "\n",
    "base_url = \"http://www.tripadvisor.com\"\n",
    "user_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.76 Safari/537.36\"\n",
    "\n",
    "\"\"\" STEP 1  \"\"\"\n",
    "def get_tourism_page(city, state):\n",
    "    \"\"\" \n",
    "        Return the json containing the\n",
    "        URL of the tourism city page\n",
    "    \"\"\"\n",
    "\n",
    "    # EXAMPLE: http://www.tripadvisor.com/TypeAheadJson?query=boston%20massachusetts&action=API\n",
    "    #          http://www.tripadvisor.com//TypeAheadJson?query=san%20francisco%20california&type=GEO&action=API\n",
    "    url = \"%s/TypeAheadJson?query=%s%%20%s&action=API\" % (base_url, \"%20\".join(city.split()), state)\n",
    "    print \"URL TO REQUEST:\", url\n",
    "    \n",
    "    # Given the url, request the HTML page\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    html = response.text.encode('utf-8')\n",
    "\n",
    "    # Save to file\n",
    "    #with open('search-page.json', \"w\") as h:\n",
    "        #h.write(html)\n",
    "\n",
    "    # Parse json to get url\n",
    "    js = json.loads(html)\n",
    "    results = js['results']\n",
    "    print \"RESULTS: \", results[0]\n",
    "    urls = results[0]['urls'][0]\n",
    "\n",
    "    # get tourism page url\n",
    "    tourism_url = urls['url']\n",
    "    return tourism_url\n",
    "\n",
    "\"\"\" STEP 2  \"\"\"\n",
    "def get_city_page(tourism_url):\n",
    "    \"\"\" \n",
    "        Get the URL of the hotels of the city\n",
    "        using the URL returned by the function\n",
    "        get_tourism_page()\n",
    "    \"\"\"\n",
    "\n",
    "    url = base_url + tourism_url\n",
    "\n",
    "    # Given the url, request the HTML page\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    html = response.text.encode('utf-8')\n",
    "    \n",
    "    # Save to file\t\n",
    "    #with open('-tourism-page.html', \"w\") as h:\n",
    "        #h.write(html)\n",
    "\n",
    "\n",
    "    # Use BeautifulSoup to extract the url for the list of hotels in \n",
    "    # the city and state we are interested in.\n",
    "    # For exampel in this case we need to  \n",
    "    #<li class=\"hotels twoLines\">\n",
    "    #<a href=\"/Hotels-g60745-Boston_Massachusetts-Hotels.html\" data-trk=\"hotels_nav\"\n",
    "    soup = BeautifulSoup(html)\n",
    "    li = soup.find(\"li\", {\"class\": \"hotels twoLines\"})\n",
    "    city_url = li.find('a', href = True)\n",
    "    print \"CITY PAGE URL:\", city_url['href']\n",
    "    return city_url['href']\n",
    "\n",
    "\n",
    "\"\"\" STEP 3 \"\"\"\n",
    "def get_hotellist_page(city_url, count):\n",
    "    \"\"\" Get the hotel list page given the url returned by\n",
    "        get_city_page(). Return the html after saving\n",
    "        it to the datadir \n",
    "    \"\"\"\n",
    "    print \"Hotel page\", count\n",
    "    url = base_url + city_url\n",
    "    # Sleep 2 sec before starting a new http request\n",
    "    time.sleep(2)\n",
    "    # Request page\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    html = response.text.encode('utf-8')\n",
    "    # Save the \n",
    "    #with open('boston-hotelist-' + str(count) + '.html', \"w\") as h:\n",
    "        #h.write(html)\n",
    "    return html\n",
    "\n",
    "\"\"\" STEP 4 \"\"\"\n",
    "def parse_hotellist_page(html):\n",
    "    \"\"\" \n",
    "    Parse the html pages returned by get_hotellist_page().\n",
    "    Return the next url page to scrape (a city can have\n",
    "    more than one page of hotels) if there is, else exit\n",
    "    the script.\n",
    "    \"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(html)\n",
    "# Extract hotel name, star rating and number of reviews\n",
    "    hotel_boxes = soup.findAll('div', {'class' :'listing easyClear  p13n_imperfect '})\n",
    "    print len(hotel_boxes), \"hotels\"\n",
    "    for hotel_box in hotel_boxes:\n",
    "        name = hotel_box.find('div', {'class' :'listing_title'}).find(text=True)\n",
    "        try:\n",
    "            rating = hotel_box.find('div', {'class' :'listing_rating'})\n",
    "            reviews = rating.find('span', {'class' :'more'}).find(text=True)\n",
    "            stars = hotel_box.find(\"img\", {\"class\" : \"sprite-ratings\"})\n",
    "        except Exception, e:\n",
    "            print \"no ratings for\", name\n",
    "            reviews = \"N/A\"\n",
    "            stars = 'N/A'\n",
    "        hotelref = hotel_box.findAll('a', href= True)\n",
    "        #print \"go to \", hotelref[0]['href'],\" and get traveler ratings\"\n",
    "        print name,\n",
    "        ratingfile.write(\"++NEW HOTEL++ %s\\n\" % name)\n",
    "        print '.',\n",
    "        getTraverlerRating(hotelref[0]['href'])\n",
    "        \n",
    "        \n",
    "        if stars != 'N/A':\n",
    "            #log.info(\"Stars: %s\" % stars['alt'].split()[0])\n",
    "            stars = stars['alt'].split()[0]\n",
    "        if name == \"Omni Parker House\":\n",
    "            print \"Found Omni Parker House. Scrape reviews\"\n",
    "            print \"HOTEL NAME:\", name\n",
    "            print \"HOTEL REVIEWS: \", reviews\n",
    "            print \"HOTEL STAR RATING:\", stars\n",
    "            omnihrefs = hotel_box.findAll('a', href= True)\n",
    "            for omnihref in omnihrefs:\n",
    "                #print omnihref, \"######\", omnihref['href']\n",
    "                if omnihref.find(text = True) == 'Omni Parker House':\n",
    "                    \n",
    "                    pg = 0\n",
    "                    #print \"Review url is\", omnihref['href']\n",
    "                    #print \"page #\", pg,\n",
    "                    #REMOVE COMMENT ret = scrapeReview(omnihref['href'], pg)\n",
    "                    ret = scrapeFaster(omnihref['href'])                    \n",
    "                    \n",
    "                    while ret:\n",
    "                        pg +=1\n",
    "                        print \"page #\", pg, \n",
    "                        ret = scrapeReview(ret, pg)\n",
    "                    print \"Done scraping omni hotel\"\n",
    "                    \"\"\"\n",
    "                    print \"Review url begin:\", omnihref['href'] \n",
    "                    scrapeReview(omnihref['href'])\n",
    "                    \"\"\"\n",
    "                    #add this block in main flow to scrape everything\n",
    "                #return\n",
    "\n",
    "# # Get next URL page if exists, else exit\n",
    "    div = soup.find(\"div\", {\"class\" : \"unified pagination standard_pagination\"})\n",
    "    # check if last page\n",
    "    if div.find('span', {'class' : 'nav next ui_button disabled'}):\n",
    "        print \"\\nReached last page\"\n",
    "        return None\n",
    "    # If it is not las page there must be the Next URL\n",
    "    hrefs = div.findAll('a', href= True)\n",
    "    for href in hrefs:\n",
    "        if href.find(text = True) == 'Next':\n",
    "            print \"Next url is\", href['href']\n",
    "            return href['href']\n",
    "\n",
    "\"\"\"Get Traverler's ratings for every hotel\"\"\"\n",
    "def getTraverlerRating(hotelurl):\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "    response = requests.get(base_url+hotelurl, headers=headers)\n",
    "    #print response\n",
    "    html = response.text.encode('utf-8')   \n",
    "    hotelsoup = BeautifulSoup(html)\n",
    "    \n",
    "    try: \n",
    "        filterbox = hotelsoup.findAll(\"div\",{\"class\":\"with_histogram\"})\n",
    "        ratebox = filterbox[0].findAll(\"div\",{\"class\":\"col rating \"})\n",
    "        ratinglist = ratebox[0].findAll(\"li\")\n",
    "        excel = ratinglist[0].findAll(\"label\",{\"for\":\"taplc_prodp13n_hr_sur_review_filter_controls_0_filterRating_5\"})[0]\n",
    "        ratingfile.write(\"Excellent:%s\\n\" % excel.findAll(\"span\")[2].find(text=True))\n",
    "        #print \"excel\", excel.findAll(\"span\")[2].find(text=True), \n",
    "        vgood = ratinglist[1].findAll(\"label\",{\"for\":\"taplc_prodp13n_hr_sur_review_filter_controls_0_filterRating_4\"})[0]\n",
    "        ratingfile.write(\"Very good: %s\\n\" % vgood.findAll(\"span\")[2].find(text=True))\n",
    "\n",
    "        avg = ratinglist[2].findAll(\"label\",{\"for\":\"taplc_prodp13n_hr_sur_review_filter_controls_0_filterRating_3\"})[0]\n",
    "        ratingfile.write(\"Average:%s\\n\" % avg.findAll(\"span\")[2].find(text=True))\n",
    "\n",
    "        poor = ratinglist[3].findAll(\"label\",{\"for\":\"taplc_prodp13n_hr_sur_review_filter_controls_0_filterRating_2\"})[0]\n",
    "        ratingfile.write(\"Poor:%s\\n\" % poor.findAll(\"span\")[2].find(text=True))\n",
    "\n",
    "        terrible = ratinglist[4].findAll(\"label\",{\"for\":\"taplc_prodp13n_hr_sur_review_filter_controls_0_filterRating_1\"})[0]\n",
    "        ratingfile.write(\"Terrible:%s\\n\" % terrible.findAll(\"span\")[2].find(text=True))\n",
    "\n",
    "        typebox = filterbox[0].findAll(\"div\",{\"class\":\"col segment \"})\n",
    "        typelist = typebox[0].findAll(\"li\")\n",
    "\n",
    "        ratingfile.write(\"Traveler type: \")\n",
    "        #print 'travel'\n",
    "        for t in typelist:\n",
    "            typevallist = t.findAll(\"span\")[1].find(text=True)\n",
    "            #print typevallist,\n",
    "            ratingfile.write(\"%s, \" % typevallist)\n",
    "        ratingfile.write(\"\\n\")\n",
    "        #print \".\"\n",
    "        \n",
    "    except IndexError:\n",
    "        print \"no rating for\", base_url+hotelurl\n",
    "        return\n",
    "    \n",
    "    \n",
    "     \n",
    "    #sys.exit()\n",
    "        \n",
    "\"\"\"STEP 5: Go through each review\"\"\"   \n",
    "\"\"\"\n",
    "def scrapeFaster(url):\n",
    "    driver.get(base_url+url)\n",
    "    \n",
    "    pagehtml = driver.page_source\n",
    "    pgsoup = BeautifulSoup(pagehtml)\n",
    "    try:\n",
    "        nexturl = driver.find_element_by_link_text(\"More\")\n",
    "        print \"More BUTTON\", nexturl\n",
    "    except NoSuchElementException:\n",
    "        print \"NO LINK\"\n",
    "        return\n",
    "    nexturl.click() \n",
    "    time.sleep(0.2)\n",
    "    \n",
    "    print \"page loaded\"\n",
    "\"\"\"    \n",
    "\n",
    "\n",
    "def scrapeReview(reviewurl, pgnum):\n",
    "    #return\n",
    "    #print base_url+reviewurl\n",
    "    # debug pupose reviewurl = globalurl\n",
    "    debugfile.write(\"\\nscrapeReview: url %s,\" % base_url+reviewurl)\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "    response = requests.get(base_url+reviewurl, headers=headers)\n",
    "    #print response\n",
    "    debugfile.write(\"scrapeReview: response %s\\n\" % response)\n",
    "    html = response.text.encode('utf-8')   \n",
    "    reviewsoup = BeautifulSoup(html) \n",
    "    \n",
    "    revbox = reviewsoup.findAll(\"div\", {\"class\":\"reviewSelector   track_back\"})\n",
    "    olderrevbox = reviewsoup.findAll(\"div\", {\"class\":\"reviewSelector  \"})\n",
    "    oldestbox = reviewsoup.findAll(\"div\", {\"class\":\"reviewSelector  first_aph   track_back\"})\n",
    "    \n",
    "    #if len(olderrevbox):\n",
    "        #print \"older reviews\", len(olderrevbox)\n",
    "    debugfile.write(\"scrapeReview: total reviews to be parsed %s\\n\" % str(len(revbox)+len(olderrevbox)+len(oldestbox)))\n",
    "    print \"(\",len(revbox)+len(olderrevbox)+len(oldestbox),\")|\",\n",
    "    pg = 1\n",
    "    revbox += olderrevbox+oldestbox\n",
    "    \n",
    "    #click on more button and send expanded cells to getstars2 one-by-one?\n",
    "    for r in revbox:\n",
    "        reviews = r.findAll('a', href=True)        \n",
    "        for rev in reviews:            \n",
    "            thisrevurl = rev['href']\n",
    "            #print thisrevurl\n",
    "            #now make http request for review url and write values to a file\n",
    "            getStars2(thisrevurl)\n",
    "            \n",
    "    #debug purpose sys.exit()\n",
    "    \n",
    "    \"\"\"\n",
    "    reviews = revbox[0].findAll('a', href=True)\n",
    "    thisurl = reviews[0]['href']\n",
    "    nextpageret = getStars(thisurl,0)\n",
    "    \"\"\"\n",
    "    \n",
    "    #nextpages = reviewsoup.findAll(\"a\", {\"class\":\"pageNum taLnk\"})\n",
    "    \"\"\"\n",
    "    print \"next review page\", nextpageret\n",
    "    while nextpageret:        \n",
    "        pg +=1\n",
    "        print \"Next review page #\", pg        \n",
    "        #nextpageret = getStars(nextpageret, pg)\n",
    "    \"\"\"\n",
    "    nextpages = reviewsoup.findAll(\"a\", {\"class\":\"pageNum taLnk\"})\n",
    "    pgnum = min(pgnum,4)\n",
    "    try:\n",
    "        #print \"\\nnext page?\", nextpages[pgnum]['href']\n",
    "        debugfile.write(\"scrapeReview: next page url %s\\n\" % nextpages[pgnum]['href'])\n",
    "        return nextpages[pgnum]['href']\n",
    "    except IndexError:\n",
    "        print \"Done with all pages\", pgnum\n",
    "        return None\n",
    "\n",
    "\"\"\"STEP 6 : Access individual review, parse ratings and store in a file\"\"\"\n",
    "def getStars2(revurl):\n",
    "    #print base_url+revurl,\n",
    "    debugfile.write(\"getStars2: url %s,\" % base_url+revurl)\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "    response = requests.get(base_url+revurl, headers=headers)\n",
    "    #print response\n",
    "    debugfile.write(\"getStars2: response %s\\n\" % response)\n",
    "    html = response.text.encode('utf-8') \n",
    "    \n",
    "    reviewsoup = BeautifulSoup(html)\n",
    "    reviewblock = reviewsoup.findAll(\"div\",{\"class\":\"deckC\"})\n",
    "    try:\n",
    "        reviewlist = reviewblock[0].findAll(\"div\",{\"class\":\"  reviewSelector \"})\n",
    "    except IndexError:\n",
    "        return\n",
    "    review = reviewlist[0]\n",
    "    \n",
    "            \n",
    "    #print review\n",
    "    id = review['id']\n",
    "    #print id, \n",
    "    debugfile.write(\"getStars2: id: %s\\t\" % id)\n",
    "    ratelist = review.findAll(\"div\", {\"class\":\"rating-list\"})\n",
    "    #print ratelist\n",
    "    try:\n",
    "        stars = ratelist[0].findAll(\"li\",{\"class\":\"recommend-answer\"})\n",
    "    except IndexError:\n",
    "        return\n",
    "    #inside stars, access sprite and description and write\n",
    "    #print stars\n",
    "    #ratedict = collections.defaultdict(list)\n",
    "    for val in stars:\n",
    "        v = val.findAll(\"img\")\n",
    "        k = val.findAll(\"div\",{\"class\":\"recommend-description\"})\n",
    "        #print k,v\n",
    "        #print id, \":\",k[0].find(text=True),\":\", v[0]['alt'][0]\n",
    "        #ratedict[k[0].find(text=True)] = v[0]['alt'][0]\n",
    "\n",
    "        try:\n",
    "            access = k[0],v[0]\n",
    "        except IndexError:\n",
    "            continue\n",
    "        omnifile.write(\"%s:\" % id)\n",
    "        omnifile.write(\"%s:\" % k[0].find(text=True))\n",
    "        omnifile.write(\"%s\\n\" % v[0]['alt'][0])\n",
    "    #nextpage = reviewsoup.findAll(\"a\",{\"class\":\"pageNum taLnk\"})\n",
    "    #print \"go to next\", nextpage[0]['href']\n",
    "    #return nextpage[0]['href']\n",
    "\"\"\"\n",
    "#Try using selenium. Couldn't get this to work correctly - next page not loading\n",
    "def getStars(revurl, pg):\n",
    "    print base_url+revurl\n",
    "    driver.get(base_url+revurl)\n",
    "    print \"page #\", pg\n",
    "    #time.sleep(1)\n",
    "    while True:\n",
    "        #geturl = base_url+revurl\n",
    "        #headers = { 'User-Agent' : user_agent }\n",
    "        #response = requests.get(base_url+revurl, headers=headers)\n",
    "        #print response\n",
    "        #html = response.text.encode('utf-8')   \n",
    "        \n",
    "        html = driver.page_source\n",
    "        reviewsoup = BeautifulSoup(html) \n",
    "        reviewblock = reviewsoup.findAll(\"div\",{\"class\":\"deckC\"})\n",
    "        reviewlist = reviewblock[0].findAll(\"div\",{\"class\":\"  reviewSelector \"})\n",
    "        #print reviewlist\n",
    "\n",
    "        revnum = 0\n",
    "        for review in reviewlist:        \n",
    "            \n",
    "            if pg and not revnum:\n",
    "                revnum += 1\n",
    "                continue\n",
    "            \n",
    "            #print review\n",
    "            id = review['id']\n",
    "            print id\n",
    "            ratelist = review.findAll(\"div\", {\"class\":\"rating-list\"})\n",
    "            #print ratelist\n",
    "            for i in xrange(len(ratelist)):\n",
    "\n",
    "                stars = ratelist[i].findAll(\"li\",{\"class\":\"recommend-answer\"})\n",
    "                #inside stars, access sprite and description and write\n",
    "                #print stars\n",
    "                #ratedict = collections.defaultdict(list)\n",
    "                for val in stars:\n",
    "                    v = val.findAll(\"img\")\n",
    "                    k = val.findAll(\"div\",{\"class\":\"recommend-description\"})\n",
    "                    #print k,v\n",
    "                    #print id, \":\",k[0].find(text=True),\":\", v[0]['alt'][0]\n",
    "                    #ratedict[k[0].find(text=True)] = v[0]['alt'][0]\n",
    "\n",
    "                    #omnifile.write(\"%s:\" % id)\n",
    "                    #omnifile.write(\"%s:\" % k[0].find(text=True))\n",
    "                    #omnifile.write(\"%s\\n\" % v[0]['alt'][0])\n",
    "            revnum += 1\n",
    "            \n",
    "        pg += 1\n",
    "        try:\n",
    "            nexturl = driver.find_element_by_link_text(\"Next\")\n",
    "            print \"NEXT BUTTON\", nexturl\n",
    "        except NoSuchElementException:\n",
    "            print \"NO LINK\"\n",
    "            break\n",
    "        nexturl.click() \n",
    "        body = driver.find_element_by_tag_name(\"body\")\n",
    "        body.send_keys(Keys.CONTROL + 't')\n",
    "        def link_has_gone_stale():\n",
    "            try:\n",
    "                # poll the link with an arbitrary call\n",
    "                nexturl.find_elements_by_id('doesnt-matter') \n",
    "                return False\n",
    "            except StaleElementReferenceException:\n",
    "                return True\n",
    "        time.sleep(1)\n",
    "        wait_for(link_has_gone_stale)\n",
    "        \n",
    "        nextpage = reviewsoup.findAll(\"a\",{\"class\":\"pageNum taLnk\"})\n",
    "        print \"go to next\", nextpage[0]['href']\n",
    "        revurl = nextpage[0]['href']\n",
    "    #return nextpage[0]['href']\n",
    "    #return nextpage[0]['href']\n",
    "    #omnidict[id] = ratedict\n",
    "    #print id,\":\",k,\":\", v\n",
    "    #print stars\n",
    "def wait_for(condition_function):\n",
    "    start_time = time.time()\n",
    "    while time.time() < start_time + 10:\n",
    "        if condition_function():\n",
    "            return True\n",
    "        else:\n",
    "            time.sleep(0.1)\n",
    "    raise Exception(\n",
    "        'Timeout waiting for {}'.format(condition_function.__name__)\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "#globalurl = \"/Hotel_Review-g60745-d89599-Reviews-or5270-Omni_Parker_House-Boston_Massachusetts.html#REVIEWS\"\n",
    "print 'get url'\n",
    "\n",
    "\"\"\"\n",
    "Just to be safe, adding NEWFILE to filename to avoid replacing the original complete file\n",
    "\"\"\"\n",
    "omnifile = open(\"omni-scrapte-out-NEWFILE.dat\",\"w\")\n",
    "ratingfile = open(\"travel-rating.dat-NEWFILE\",\"w\")\n",
    "debugfile = open(\"debug.log\",\"w\")\n",
    "tourism_url = get_tourism_page('boston', 'massachusetts')\n",
    "#Get URL to obtaint the list of hotels in a specific city\n",
    "city_url = get_city_page(tourism_url)\n",
    "c=0\n",
    "#driver = webdriver.Firefox()\n",
    "#driver.wait = WebDriverWait(driver, 5)\n",
    "while(True):\n",
    "    c +=1\n",
    "    html = get_hotellist_page(city_url,c)\n",
    "    city_url = parse_hotellist_page(html)\n",
    "    if not city_url:\n",
    "        break\n",
    "omnifile.close()\n",
    "ratingfile.close()\n",
    "debugfile.close()\n",
    "#driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Task 2 (20 pts) **\n",
    "\n",
    "Now, we will use regression to analyze this information. First, we will fit a linear regression model that predicts the average rating. For example, for the hotel above, the average rating is\n",
    "\n",
    "$$ \\text{AVG_SCORE} = \\frac{1*31 + 2*33 + 3*98 + 4*504 + 5*1861}{2527}$$\n",
    "\n",
    "Use the model to analyze the important factors that decide the $\\text{AVG_SCORE}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 ratings added to omnidict\n",
      "82 hotels added to dict\n",
      "Hilton Boston Downtown / Faneuil Hall missing Location\n",
      "Hilton Boston Downtown / Faneuil Hall missing Sleep Quality\n",
      "Hilton Boston Downtown / Faneuil Hall missing Rooms\n",
      "Hilton Boston Downtown / Faneuil Hall missing Service\n",
      "Hilton Boston Downtown / Faneuil Hall missing Value\n",
      "Hilton Boston Downtown / Faneuil Hall missing Cleanliness\n",
      "Residence Inn Boston Back Bay / Fenway missing Location\n",
      "Residence Inn Boston Back Bay / Fenway missing Sleep Quality\n",
      "Residence Inn Boston Back Bay / Fenway missing Rooms\n",
      "Residence Inn Boston Back Bay / Fenway missing Service\n",
      "Residence Inn Boston Back Bay / Fenway missing Value\n",
      "Residence Inn Boston Back Bay / Fenway missing Cleanliness\n",
      "Element Boston Seaport missing Location\n",
      "Generated 82 lists for all hotels\n",
      "Now feed all these 82 vectors to fit a model\n",
      "(82, 17)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               Avgscore   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 4.849e+29\n",
      "Date:                Mon, 28 Mar 2016   Prob (F-statistic):               0.00\n",
      "Time:                        17:24:52   Log-Likelihood:                 1918.2\n",
      "No. Observations:                  81   AIC:                            -3802.\n",
      "Df Residuals:                      64   BIC:                            -3762.\n",
      "Df Model:                          16                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept     4.547e-13   1.03e-11      0.044      0.965     -2.02e-11  2.11e-11\n",
      "Excellent        5.0000   5.51e-14   9.08e+13      0.000         5.000     5.000\n",
      "Verygood         4.0000   5.57e-14   7.18e+13      0.000         4.000     4.000\n",
      "Average          3.0000   9.99e-14      3e+13      0.000         3.000     3.000\n",
      "Poor             2.0000   1.62e-13   1.23e+13      0.000         2.000     2.000\n",
      "Terrible         1.0000    1.5e-13   6.68e+12      0.000         1.000     1.000\n",
      "Families      4.263e-14   6.56e-14      0.650      0.518     -8.84e-14  1.74e-13\n",
      "Couples       7.105e-15   6.45e-14      0.110      0.913     -1.22e-13  1.36e-13\n",
      "Solo          1.776e-14   7.76e-14      0.229      0.820     -1.37e-13  1.73e-13\n",
      "Business      8.882e-15    5.7e-14      0.156      0.877     -1.05e-13  1.23e-13\n",
      "Friends       4.974e-14   7.51e-14      0.662      0.510        -1e-13     2e-13\n",
      "Location     -1.137e-13    3.3e-12     -0.034      0.973     -6.71e-12  6.48e-12\n",
      "SleepQuality  1.592e-12   1.46e-11      0.109      0.914     -2.77e-11  3.08e-11\n",
      "Rooms        -1.819e-12   1.28e-11     -0.142      0.888     -2.74e-11  2.38e-11\n",
      "Service      -9.095e-13   1.73e-11     -0.052      0.958     -3.55e-11  3.37e-11\n",
      "Value                 0   1.18e-11          0      1.000     -2.36e-11  2.36e-11\n",
      "Cleanliness   2.728e-12   1.92e-11      0.142      0.887     -3.55e-11   4.1e-11\n",
      "==============================================================================\n",
      "Omnibus:                       49.980   Durbin-Watson:                   1.181\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              586.992\n",
      "Skew:                           1.392   Prob(JB):                    3.44e-128\n",
      "Kurtosis:                      15.891   Cond. No.                     1.98e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.98e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "Created (82, 16) (82,)\n",
      "0    16917\n",
      "1    11260\n",
      "2    10316\n",
      "3    13567\n",
      "4     2267\n",
      "Name: Avgscore, dtype: int64\n",
      "[('Excellent', 4.9999999999999991), ('Verygood', 3.9999999999999987), ('Average', 3.000000000000008), ('Poor', 2.0000000000000018), ('Terrible', 0.99999999999998246), ('Families', -1.236694878909716e-15), ('Couples', 1.0340601919552109e-15), ('Solo', -1.9867141455488598e-15), ('Business', 4.7527248033094344e-15), ('Friends', -2.9009221316004996e-15), ('Location', -3.4594051510633637e-14), ('SleepQuality', -3.6970641901592892e-13), ('Rooms', -2.7733688218144397e-13), ('Service', 7.0677670784475804e-13), ('Value', 2.4642311305434889e-13), ('Cleanliness', -2.6105190699505751e-13)]\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import time, math\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import scipy as sp\n",
    "import scipy.sparse.linalg as linalg\n",
    "import scipy.cluster.hierarchy as hr\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "import sklearn.datasets as datasets\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.utils as utils\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.cross_validation as cross_validation\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from patsy import dmatrices\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pprint\n",
    "\n",
    "def mergeOmnifile():\n",
    "    with open(\"omni-scrapte-out.dat\") as omnifile:\n",
    "        lines = omnifile.readlines()\n",
    "        for line in lines:\n",
    "            #print line.split(\":\")[1],\":\", int(line.split(\":\")[2].split(\"\\n\")[0])\n",
    "            splitline = line.split(\":\")\n",
    "            k1,k2 = splitline[1], splitline[2][:-1] \n",
    "                    \n",
    "            if k2 not in omnidict[k1]:\n",
    "                omnidict[k1][k2] = 0\n",
    "            omnidict[k1][k2] += 1                \n",
    "    \n",
    "    omnifile.close()\n",
    "\n",
    "def parseDatafiles():\n",
    "    \n",
    "    newlist = [0]\n",
    "    i = 0\n",
    "    with open(\"travel-rating.dat\") as tratefile:\n",
    "        lines = tratefile.readlines()     \n",
    "        hotelname = None\n",
    "        for line in lines:            \n",
    "            if line[0] == '+':   \n",
    "                if hotelname:\n",
    "                    #print allratedict[hotelname]\n",
    "                    for attr in attrlist:\n",
    "                        try:\n",
    "                            newlist.append(allratedict[hotelname][attr])\n",
    "                        except KeyError:\n",
    "                            print hotelname, \"missing\", attr\n",
    "                            newlist.append(0)\n",
    "                    #print newlist, len(newlist)\n",
    "                    hoteldict[hotelname] = newlist\n",
    "                    #print len(hoteldict), hotelname, i\n",
    "                i+=1\n",
    "                hotelname = line.split('+')[4][1:-1]\n",
    "                #print hotelname\n",
    "                newlist = [0]\n",
    "                avgscore = 0\n",
    "            else:\n",
    "                if line.split(\":\")[0] == \"Traveler type\":\n",
    "                    typelist = line.split(\":\")[1].split(\")\")\n",
    "                    for ttype in typelist:\n",
    "                        try:\n",
    "                            val = int(ttype.split(\"(\")[1].replace(',',''))\n",
    "                            #print val\n",
    "                            newlist.append(int(val))\n",
    "                        except IndexError:\n",
    "                            continue\n",
    "                    newlist[0] = avgscore\n",
    "                else:\n",
    "                    key = line.split(\":\")[0]\n",
    "                    val = int(line.split(\":\")[1][:-1].replace(',',''))\n",
    "                    #print key, val\n",
    "                    newlist.append(int(val))\n",
    "                    avgscore += val*avgscoredict[key]\n",
    "    if hotelname:\n",
    "        hoteldict[hotelname] = newlist\n",
    "        \n",
    "    tratefile.close()\n",
    "\n",
    "def parseRateDat():        \n",
    "    with open(\"rating-summary.dat\") as ratefile:\n",
    "        hotelratings = ratefile.readlines()\n",
    "        prevhname = None\n",
    "        newdict = collections.defaultdict(dict)\n",
    "        for line in hotelratings:\n",
    "            splitline = line.split(\":\")\n",
    "            hotelname = splitline[0]\n",
    "            if hotelname != prevhname:\n",
    "\n",
    "                appendDict(newdict, prevhname)\n",
    "                \n",
    "                prevhname = hotelname\n",
    "                #print \"###NEW###\", hotelname\n",
    "                newdict = collections.defaultdict(dict)                                \n",
    "                \n",
    "            k1,k2,v = splitline[1], splitline[2], splitline[3][:-1]\n",
    "            #print k1,k2,v\n",
    "            newdict[k1][k2] = int(v)\n",
    "        \n",
    "    appendDict(newdict, prevhname)\n",
    "    appendDict(omnidict, \"Omni Parker House\")\n",
    "    #print omnidict\n",
    "            \n",
    "    ratefile.close()\n",
    "    #print len(hoteldict)\n",
    "\n",
    "def appendDict(newdict, prevhname):\n",
    "    for k1 in newdict.keys():\n",
    "        #print k1,newdict[k1]\n",
    "        if k1 not in attrlist:\n",
    "            #print k1\n",
    "            continue\n",
    "        ratesum = 0\n",
    "        totalnum = 0\n",
    "        for k2 in newdict[k1].keys():\n",
    "\n",
    "            ratesum += int(k2)*int(newdict[k1][k2])\n",
    "            totalnum += int(newdict[k1][k2])\n",
    "        #print prevhname, k1, 1.0*ratesum/totalnum\n",
    "        score = 1.0*ratesum/totalnum\n",
    "        allratedict[prevhname][k1] = score #math.ceil(score) if (math.ceil(score)- score <0.5) else int(score) \n",
    "        #allratedict[prevhname][k1] = ratesum\n",
    "        \n",
    "attrlist = ['Location', 'Sleep Quality', 'Rooms', 'Service', 'Value', 'Cleanliness']\n",
    "avgscoredict = {\"Excellent\":5, \"Very good\":4, \"Average\":3, \"Poor\":2, \"Terrible\":1}    \n",
    "omnidict = collections.defaultdict(dict)\n",
    "#  1 avg rating, 5 traveler ratings, 5 traveler types, 6 rating attributes,\n",
    "allratedict = collections.defaultdict(dict)\n",
    "hoteldict = collections.defaultdict(list)\n",
    "\n",
    "\n",
    "mergeOmnifile()    \n",
    "print len(omnidict), \"ratings added to omnidict\"\n",
    "\n",
    "\n",
    "parseRateDat()\n",
    "print len(allratedict), \"hotels added to dict\"\n",
    "\n",
    "\n",
    "parseDatafiles()\n",
    "print \"Generated\", len(hoteldict), \"lists for all hotels\"\n",
    "print \"Now feed all these\", len(hoteldict), \"vectors to fit a model\"\n",
    "rate_vector = []\n",
    "avg_vector = []\n",
    "\n",
    "X = pd.DataFrame(v for v in hoteldict.values())\n",
    "print X.shape\n",
    "X.columns = ['Avgscore', 'Excellent', 'Verygood', 'Average', 'Poor', 'Terrible', 'Families', 'Couples', 'Solo', 'Business','Friends', 'Location', 'SleepQuality', 'Rooms', 'Service', 'Value', 'Cleanliness']\n",
    "\n",
    "#print X.head()\n",
    "\n",
    "lm = smf.ols(formula='Avgscore ~ Excellent + Verygood + Average + Poor + Terrible + Families + Couples + Solo + Business + Friends + Location + SleepQuality + Rooms + Service + Value + Cleanliness', data=X).fit()\n",
    "#lm = smf.ols(formula='Avgscore ~ Value + Location + Service + Excellent + Verygood + Average', data=X).fit()\n",
    "print lm.summary()\n",
    "data = X.fillna(0)\n",
    "\n",
    "\n",
    "# create X and y\n",
    "feature_cols = ['Excellent', 'Verygood', 'Average', 'Poor', 'Terrible', 'Families', 'Couples', 'Solo', 'Business','Friends', 'Location', 'SleepQuality', 'Rooms', 'Service', 'Value', 'Cleanliness']\n",
    "X = data[feature_cols]\n",
    "y = data.Avgscore\n",
    "\n",
    "print \"Created\", X.shape, y.shape\n",
    "print y.head()\n",
    "#print X,y\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X, y)\n",
    "\n",
    "# print coefficients\n",
    "print zip(feature_cols, lm.coef_)\n",
    "\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Task 3 (30 pts) **\n",
    "\n",
    "Finally, we will use logistic regression to decide if a hotel is _excellent_ or not. We classify a hotel as _excellent_ if more than **60%** of its ratings are 5 stars. This is a binary attribute on which we can fit a logistic regression model. As before, use the model to analyze the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Use the same datastructured parsed in previous part:_ Please execute previous cell before proceeding (one takes a second or two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 hotels added true/false\n",
      "(82, 1)\n",
      "  isExcellent\n",
      "0        True\n",
      "1        True\n",
      "2       False\n",
      "3       False\n",
      "4        True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.582810\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            isExcellent   No. Observations:                   82\n",
      "Model:                          Logit   Df Residuals:                       66\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 28 Mar 2016   Pseudo R-squ.:                  0.1125\n",
      "Time:                        18:17:17   Log-Likelihood:                -47.790\n",
      "converged:                       True   LL-Null:                       -53.850\n",
      "                                        LLR p-value:                    0.6699\n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "--------------------------------------------------------------------------------\n",
      "Excellent       -0.0070      0.009     -0.776      0.438        -0.025     0.011\n",
      "Verygood        -0.0155      0.010     -1.618      0.106        -0.034     0.003\n",
      "Average          0.0105      0.016      0.648      0.517        -0.021     0.042\n",
      "Poor            -0.0217      0.026     -0.839      0.402        -0.072     0.029\n",
      "Terrible        -0.0040      0.024     -0.165      0.869        -0.051     0.043\n",
      "Families         0.0086      0.011      0.803      0.422        -0.012     0.030\n",
      "Couples          0.0123      0.011      1.145      0.252        -0.009     0.033\n",
      "Solo            -0.0084      0.013     -0.656      0.512        -0.034     0.017\n",
      "Business         0.0088      0.009      0.935      0.350        -0.010     0.027\n",
      "Friends          0.0051      0.012      0.411      0.681        -0.019     0.030\n",
      "Location         0.7046      0.641      1.100      0.272        -0.551     1.961\n",
      "SleepQuality    -2.8488      2.450     -1.163      0.245        -7.651     1.954\n",
      "Rooms           -2.2269      2.206     -1.009      0.313        -6.551     2.097\n",
      "Service         -0.3611      2.761     -0.131      0.896        -5.773     5.050\n",
      "Value            0.2133      1.881      0.113      0.910        -3.474     3.900\n",
      "Cleanliness      4.2417      3.257      1.302      0.193        -2.142    10.625\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def parseExcellent():        \n",
    "    with open(\"rating-summary.dat\") as ratefile:\n",
    "        hotelratings = ratefile.readlines()\n",
    "        prevhname = None\n",
    "        newdict = collections.defaultdict(dict)\n",
    "        for line in hotelratings:\n",
    "            splitline = line.split(\":\")\n",
    "            hotelname = splitline[0]\n",
    "            if hotelname != prevhname:\n",
    "\n",
    "                appendExcel(newdict, prevhname)\n",
    "                \n",
    "                prevhname = hotelname\n",
    "                #print \"###NEW###\", hotelname\n",
    "                newdict = collections.defaultdict(dict)                                \n",
    "                \n",
    "            k1,k2,v = splitline[1], splitline[2], splitline[3][:-1]\n",
    "            #print k1,k2,v\n",
    "            newdict[k1][k2] = int(v)\n",
    "        \n",
    "    appendExcel(newdict, prevhname)\n",
    "    appendExcel(omnidict, \"Omni Parker House\")\n",
    "    #print omnidict\n",
    "            \n",
    "    ratefile.close()\n",
    "    #print len(hoteldict)\n",
    "\n",
    "def appendExcel(d, n):\n",
    "    totalrev = 0\n",
    "    maxstar = 0\n",
    "    for k1 in d.keys():\n",
    "        \n",
    "        for k2 in d[k1].keys():\n",
    "            if k2 == '5':\n",
    "                maxstar +=d[k1][k2]\n",
    "            totalrev+=d[k1][k2]\n",
    "    if totalrev == 0:\n",
    "        #print n, \"000000000\"\n",
    "        return\n",
    "    #print n, 1.0*maxstar/totalrev >= 0.6\n",
    "    exceldict[n] = 1.0*maxstar/totalrev >= 0.6\n",
    "        \n",
    "exceldict = collections.defaultdict()\n",
    "parseExcellent()\n",
    "print len(exceldict), \"hotels added true/false\"\n",
    "\n",
    "y = pd.DataFrame(v for v in exceldict.values())\n",
    "print y.shape\n",
    "y.columns = ['isExcellent']\n",
    "print y.head()\n",
    "\n",
    "excelfit = sm.Logit(y, X[feature_cols])\n",
    " \n",
    "# fit the model\n",
    "result = excelfit.fit() \n",
    "print result.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code for setting the style of the notebook\n",
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"../../theme/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
