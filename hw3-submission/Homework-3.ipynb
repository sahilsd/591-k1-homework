{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(In order to load the stylesheet of this notebook, execute the last code cell in this notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Hotel Ratings on Tripadvisor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework we will focus on practicing two techniques: web scraping and regression. For the first part, we will get some basic information for each hotel in Boston. Then, we will fit a regression model on this information and try to analyze it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Task 1 (30 pts)**\n",
    "\n",
    "We will scrape the data using Beautiful Soup. For each hotel that our search returns, we will get the information below.\n",
    "\n",
    "![Information to be scraped](hotel_info.png)\n",
    "\n",
    "Of course, feel free to collect even more data if you want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get url\n",
      "URL TO REQUEST: http://www.tripadvisor.com/TypeAheadJson?query=boston%20massachusetts&action=API\n",
      "RESULTS:  {u'lookbackServlet': None, u'name': u'Boston, Massachusetts, United States', u'data_type': u'LOCATION', u'title': u'Destinations', u'url': u'/Tourism-g60745-Boston_Massachusetts-Vacations.html', u'value': 60745, u'coords': u'42.357277,-71.05834', u'urls': [{u'url': u'/Tourism-g60745-Boston_Massachusetts-Vacations.html', u'type': u'GEO', u'name': u'Boston Tourism', u'url_type': u'geo'}], u'scope': u'global', u'type': u'GEO'}\n",
      "CITY PAGE URL: /Hotels-g60745-Boston_Massachusetts-Hotels.html\n",
      "Hotel page 1\n",
      "30 hotels\n",
      "Omni Parker House . Found Omni Parker House. Scrape reviews\n",
      "HOTEL NAME: Omni Parker House\n",
      "HOTEL REVIEWS:  5,620 Reviews\n",
      "HOTEL STAR RATING: 4\n",
      "page # 0 , ( 10 )| page # 1 ( 10 )| page # 2 ( 10 )| page # 3 ( 10 )| page # 4 ( 10 )| page # 5 ( 10 )| page # 6 ( 10 )| page # 7 ( 10 )| page # 8 ( 10 )| page # 9 ( 10 )| page # 10 ( 10 )| page # 11 ( 10 )| page # 12 ( 10 )| page # 13 ( 10 )| page # 14 ( 10 )| page # 15 ( 10 )| page # 16 ( 10 )| page # 17 ( 10 )| page # 18 ( 10 )| page # 19 ( 10 )| page # 20 ( 10 )| page # 21 ( 10 )| page # 22 ( 10 )| page # 23 ( 10 )| page # 24 ( 10 )| page # 25 ( 10 )| page # 26 ( 10 )| page # 27 ( 10 )| page # 28 ( 10 )| page # 29 ( 10 )| page # 30 ( 10 )| page # 31 ( 10 )| page # 32 ( 10 )| page # 33 ( 10 )| page # 34 ( 10 )| page # 35 ( 10 )| page # 36 ( 10 )| page # 37 ( 10 )| page # 38 ( 10 )| page # 39 ( 10 )| page # 40 ( 10 )| page # 41 ( 10 )| page # 42 ( 10 )| page # 43 ( 10 )| page # 44 ( 10 )| page # 45 ( 10 )| page # 46 ( 10 )| page # 47 ( 10 )| page # 48 ( 10 )| page # 49 ( 10 )| page # 50 ( 10 )| page # 51 ( 10 )| page # 52 ( 10 )| page # 53 ( 10 )| page # 54 ( 10 )| page # 55 ( 10 )| page # 56 ( 10 )| page # 57 ( 10 )| page # 58 ( 10 )| page # 59 ( 10 )| page # 60 ( 10 )| page # 61 ( 10 )| page # 62 ( 10 )| page # 63 ( 10 )| page # 64 ( 10 )| page # 65 ( 10 )| page # 66 ( 10 )| page # 67 ( 10 )| page # 68 ( 10 )| page # 69 ( 10 )| page # 70 ( 10 )| page # 71 ( 10 )| page # 72 ( 10 )| page # 73 ( 10 )| page # 74 ( 10 )| page # 75 ( 10 )| page # 76 ( 10 )| page # 77 ( 10 )| page # 78 ( 10 )| page # 79 ( 10 )| page # 80 ( 10 )| page # 81 ( 10 )| page # 82 ( 10 )| page # 83 ( 10 )| page # 84 ( 10 )| page # 85 ( 10 )| page # 86 ( 10 )| page # 87 ( 10 )| page # 88 ( 10 )| page # 89 ( 10 )| page # 90 ( 10 )| page # 91 ( 10 )| page # 92 ( 10 )| page # 93 ( 10 )| page # 94 ( 10 )| page # 95 ( 10 )| page # 96 ( 10 )| page # 97 ( 10 )| page # 98 ( 10 )| page # 99 ( 10 )| page # 100 ( 10 )| page # 101 ( 10 )| page # 102 ( 10 )| page # 103 ( 10 )| page # 104 ( 10 )| page # 105 ( 10 )| page # 106 ( 10 )| page # 107 ( 10 )| page # 108 ( 10 )| page # 109 ( 10 )| page # 110 ( 10 )| page # 111 ( 10 )| page # 112 ( 10 )| page # 113 ( 10 )| page # 114 ( 10 )| page # 115 ( 10 )| page # 116 ( 10 )| page # 117 ( 10 )| page # 118 ( 10 )| page # 119 ( 10 )| page # 120 ( 10 )| page # 121 ( 10 )| page # 122 ( 10 )| page # 123 ( 10 )| page # 124 ( 10 )| page # 125 ( 10 )| page # 126 ( 10 )| page # 127 ( 10 )| page # 128 ( 10 )| page # 129 ( 10 )| page # 130 ( 10 )| page # 131 ( 10 )| page # 132 ( 10 )| page # 133 ( 10 )| page # 134 ( 10 )| page # 135 ( 10 )| page # 136 ( 10 )| page # 137 ( 10 )| page # 138 ( 10 )| page # 139 ( 10 )| page # 140 ( 10 )| page # 141 ( 10 )| page # 142 ( 10 )| page # 143 ( 10 )| page # 144 ( 10 )| page # 145 ( 10 )| page # 146 ( 10 )| page # 147 ( 10 )| page # 148 ( 10 )| page # 149 ( 10 )| page # 150 ( 10 )| page # 151 ( 10 )| page # 152 ( 10 )| page # 153 ( 10 )| page # 154 ( 10 )| page # 155 ( 10 )| page # 156 ( 10 )| page # 157 ( 10 )| page # 158 ( 10 )| page # 159 ( 10 )| page # 160 ( 10 )| page # 161 ( 10 )| page # 162 ( 10 )| page # 163 ( 10 )| page # 164 ( 10 )| page # 165 ( 10 )| page # 166 ( 10 )| page # 167 ( 10 )| page # 168 ( 10 )| page # 169 ( 10 )| page # 170 ( 10 )| page # 171 ( 10 )| page # 172 ( 10 )| page # 173 ( 10 )| page # 174 ( 10 )| page # 175 ( 10 )| page # 176 ( 10 )| page # 177 ( 10 )| page # 178 ( 10 )| page # 179 ( 10 )| page # 180 ( 10 )| page # 181 ( 10 )| page # 182 ( 10 )| page # 183 ( 10 )| page # 184 ( 10 )| page # 185 ( 10 )| page # 186 ( 10 )| page # 187 ( 10 )| page # 188 ( 10 )| page # 189 ( 10 )| page # 190 ( 10 )| page # 191 ( 10 )| page # 192 ( 10 )| page # 193 ( 10 )| page # 194 ( 10 )| page # 195 ( 10 )| page # 196 ( 10 )| page # 197 ( 10 )| page # 198 ( 10 )| page # 199 ( 10 )| page # 200 ( 10 )| page # 201 ( 10 )| page # 202 ( 10 )| page # 203 ( 10 )| page # 204 ( 10 )| page # 205 ( 10 )| page # 206 ( 10 )| page # 207 ( 10 )| page # 208 ( 10 )| page # 209 ( 10 )| page # 210 ( 10 )| page # 211 ( 10 )| page # 212 ( 10 )| page # 213 ( 10 )| page # 214 ( 10 )| page # 215 ( 10 )| page # 216 ( 10 )| page # 217 ( 10 )| page # 218 ( 10 )| page # 219 ( 10 )| page # 220 ( 10 )| page # 221 ( 10 )| page # 222 ( 10 )| page # 223 ( 10 )| page # 224 ( 10 )| page # 225 ( 10 )| page # 226 ( 10 )| page # 227 ( 10 )| page # 228 ( 10 )| page # 229 ( 10 )| page # 230 ( 10 )| page # 231 ( 10 )| page # 232 ( 10 )| page # 233 ( 10 )| page # 234 ( 10 )| page # 235 ( 10 )| page # 236 ( 10 )| page # 237 ( 10 )| page # 238 ( 10 )| page # 239 ( 10 )| page # 240 ( 10 )| page # 241 ( 10 )| page # 242 ( 10 )| page # 243 ( 10 )| page # 244 ( 10 )| page # 245 ( 10 )| page # 246 ( 10 )| page # 247 ( 10 )| page # 248 ( 10 )| page # 249 ( 10 )| page # 250 ( 10 )| page # 251 ( 10 )| page # 252 ( 10 )| page # 253 ( 10 )| page # 254 ( 10 )| page # 255 ( 10 )| page # 256 ( 10 )| page # 257 ( 10 )| page # 258 ( 10 )| page # 259 ( 10 )| page # 260 ( 10 )| page # 261 ( 10 )| page # 262 ( 10 )| page # 263 ( 10 )| page # 264 ( 10 )| page # 265 ( 10 )| page # 266 ( 10 )| page # 267 ( 10 )| page # 268 ( 10 )| page # 269 ( 10 )| page # 270 ( 10 )| page # 271 ( 10 )| page # 272 ( 10 )| page # 273 ( 10 )| page # 274 ( 10 )| page # 275 ( 10 )| page # 276 ( 10 )| page # 277 ( 10 )| page # 278 ( 10 )| page # 279 ( 10 )| page # 280 ( 10 )| page # 281 ( 10 )| page # 282 ( 10 )| page # 283 ( 10 )| page # 284 ( 10 )| page # 285 ( 10 )| page # 286 ( 10 )| page # 287 ( 10 )| page # 288 ( 10 )| page # 289 ( 10 )| page # 290 ( 10 )| page # 291 ( 10 )| page # 292 ( 10 )| page # 293 ( 10 )| page # 294 ( 10 )| page # 295 ( 10 )| page # 296 ( 10 )| page # 297 ( 10 )| page # 298 ( 10 )| page # 299 ( 10 )| page # 300 ( 10 )| page # 301 ( 10 )| page # 302 ( 10 )| page # 303 ( 10 )| page # 304 ( 10 )| page # 305 ( 10 )| page # 306 ( 10 )| page # 307 ( 10 )| page # 308 ( 10 )| page # 309 ( 10 )| page # 310 ( 10 )| page # 311 ( 10 )| page # 312 ( 10 )| page # 313 ( 10 )| page # 314 ( 10 )| page # 315 ( 10 )| page # 316 ( 10 )| page # 317 ( 10 )| page # 318 ( 10 )| page # 319 ( 10 )| page # 320 ( 10 )| page # 321 ( 10 )| page # 322 ( 10 )| page # 323 ( 10 )| page # 324 ( 10 )| page # 325 ( 10 )| page # 326 ( 10 )| page # 327 ( 10 )| page # 328 ( 10 )| page # 329 ( 10 )| page # 330 ( 10 )| page # 331 ( 10 )| page # 332 ( 10 )| page # 333 ( 10 )| page # 334 ( 10 )| page # 335 ( 10 )| page # 336 ( 10 )| page # 337 ( 10 )| page # 338 ( 10 )| page # 339 ( 10 )| page # 340 ( 10 )| page # 341 ( 10 )| page # 342 ( 10 )| page # 343 ( 10 )| page # 344 ( 10 )| page # 345 ( 10 )| page # 346 ( 10 )| page # 347 ( 10 )| page # 348 ( 10 )| page # 349 ( 10 )| page # 350 ( 10 )| page # 351 ( 10 )| page # 352 ( 10 )| page # 353 ( 10 )| page # 354 ( 10 )| page # 355 ( 10 )| page # 356 ( 10 )| page # 357 ( 10 )| page # 358 ( 10 )| page # 359 ( 10 )| page # 360 ( 10 )| page # 361 ( 10 )| page # 362 ( 10 )| page # 363 ( 10 )| page # 364 ( 10 )| page # 365 ( 10 )| page # 366 ( 10 )| page # 367 ( 10 )| page # 368 ( 10 )| page # 369 ( 10 )| page # 370 ( 10 )| page # 371 ( 10 )| page # 372 ( 10 )| page # 373 ( 10 )| page # 374 ( 10 )| page # 375 ( 10 )| page # 376 ( 10 )| page # 377 ( 10 )| page # 378 ( 10 )| page # 379 ( 10 )| page # 380 ( 10 )| page # 381 ( 10 )| page # 382 ( 10 )| page # 383 ( 10 )| page # 384 ( 10 )| page # 385 ( 10 )| page # 386 ( 10 )| page # 387 ( 10 )| page # 388 ( 10 )| page # 389 ( 10 )| page # 390 ( 10 )| page # 391 ( 10 )| page # 392 ( 10 )| page # 393 ( 10 )| page # 394 ( 10 )| page # 395 ( 10 )| page # 396 ( 10 )| page # 397 ( 10 )| page # 398 ( 10 )| page # 399 ( 10 )| page # 400 ( 10 )| page # 401 ( 10 )| page # 402 ( 10 )| page # 403 ( 10 )| page # 404 ( 10 )| page # 405 ( 10 )| page # 406 ( 10 )| page # 407 ( 10 )| page # 408 ( 10 )| page # 409 ( 10 )| page # 410 ( 10 )| page # 411 ( 10 )| page # 412 ( 10 )| page # 413 ( 10 )| page # 414 ( 10 )| page # 415 ( 10 )| page # 416 ( 10 )| page # 417 ( 10 )| page # 418 ( 10 )| page # 419 ( 10 )| page # 420 ( 10 )| page # 421 ( 10 )| page # 422 ( 10 )| page # 423 ( 10 )| page # 424 ( 10 )| page # 425 ( 10 )| page # 426 ( 10 )| page # 427 ( 10 )| page # 428 ( 10 )| page # 429 ( 10 )| page # 430 ( 10 )| page # 431 ( 10 )| page # 432 ( 10 )| page # 433 ( 10 )| page # 434 ( 10 )| page # 435 ( 10 )| page # 436 ( 10 )| page # 437 ( 10 )| page # 438 ( 10 )| page # 439 ( 10 )| page # 440 ( 10 )| page # 441 ( 10 )| page # 442 ( 10 )| page # 443 ( 10 )| page # 444 ( 10 )| page # 445 ( 10 )| page # 446 ( 10 )| page # 447 ( 10 )| page # 448 ( 10 )| page # 449 ( 10 )| page # 450 ( 10 )| page # 451 ( 10 )| page # 452 ( 10 )| page # 453 ( 10 )| page # 454 ( 10 )| page # 455 ( 10 )| page # 456 ( 10 )| page # 457 ( 10 )| page # 458 ( 10 )| page # 459 ( 10 )| page # 460 ( 10 )| page # 461 ( 10 )| page # 462 ( 10 )| page # 463 ( 10 )| page # 464 ( 10 )| page # 465 ( 10 )| page # 466 ( 10 )| page # 467 ( 10 )| page # 468 ( 10 )| page # 469 ( 10 )| page # 470 ( 10 )| page # 471 ( 10 )| page # 472 ( 10 )| page # 473 ( 10 )| page # 474 ( 10 )| page # 475 ( 10 )| page # 476 ( 10 )| page # 477 ( 10 )| page # 478 ( 10 )| page # 479 ( 10 )| page # 480 ( 10 )| page # 481 ( 10 )| page # 482 ( 10 )| page # 483 ( 10 )| page # 484 ( 10 )| page # 485 ( 10 )| page # 486 ( 10 )| page # 487 ( 10 )| page # 488 ( 10 )| page # 489 ( 10 )| page # 490 ( 10 )| page # 491 ( 10 )| page # 492 ( 10 )| page # 493 ( 10 )| page # 494 ( 10 )| page # 495 ( 10 )| page # 496 ( 10 )| page # 497 ( 10 )| page # 498 ( 10 )| page # 499 ( 10 )| page # 500 ( 10 )| page # 501 ( 10 )| page # 502 ( 10 )| page # 503 ( 10 )| page # 504 ( 10 )| page # 505 ( 10 )| page # 506 ( 10 )| page # 507 ( 10 )| page # 508 ( 10 )| page # 509 ( 10 )| page # 510 ( 10 )| page # 511 ( 10 )| page # 512 ( 10 )| page # 513 ( 10 )| page # 514 ( 10 )| page # 515 ( 10 )| page # 516 ( 10 )| page # 517 ( 10 )| page # 518 ( 10 )| page # 519 ( 10 )| page # 520 ( 10 )| page # 521 ( 10 )| page # 522 ( 10 )| page # 523 ( 10 )| page # 524 ( 10 )| page # 525 ( 10 )| page # 526 ( 10 )| page # 527 ( 10 )| page # 528 ( 10 )| page # 529 ( 10 )| page # 530 ( 10 )| page # 531 ( 10 )| page # 532 ( 10 )| page # 533 ( 10 )| page # 534 ( 6 )| Done with all pages 4\n",
      "Done scraping omni hotel\n",
      "Hyatt Regency Boston Harbor . Seaport Boston Hotel . Hotel Commonwealth . The Westin Copley Place . Revere Hotel Boston Common . Sheraton Boston Hotel . InterContinental Boston . Nine Zero Hotel - a Kimpton Hotel . Boston Harbor Hotel . Fairmont Copley Plaza, Boston . Boston Marriott Copley Place . Lenox Hotel . Courtyard by Marriott Boston Copley Square . enVision Hotel Boston . The Midtown Hotel . Boston Hotel Buckminster . Embassy Suites by Hilton Boston - at Logan Airport . The Liberty Hotel . Harborside Inn . DoubleTree Club by Hilton Hotel Boston Bayside . The Langham, Boston . Boston Marriott Long Wharf . XV Beacon . Hilton Boston Downtown / Faneuil Hall . Loews Boston Hotel . The Verb Hotel . W Boston . Holiday Inn Express Boston . Taj Boston . Next url is /Hotels-g60745-oa30-Boston_Massachusetts-Hotels.html#ACCOM_OVERVIEW\n",
      "Hotel page 2\n",
      "30 hotels\n",
      "The Bostonian Boston . Residence Inn Boston Back Bay / Fenway . Hilton Boston Back Bay . Hyatt Regency Boston . The Boxer Boston . Hilton Boston Logan Airport . Hampton Inn &amp; Suites Boston Crosstown Center . Chandler Inn . Copley House . The Westin Boston Waterfront . Copley Square Hotel . Marriott&#39;s Custom House . DoubleTree Suites by Hilton Boston-Cambridge . Residence Inn by Marriott Boston Harbor on Tudor Wharf . DoubleTree by Hilton Hotel Boston - Downtown . Colonnade Hotel . Eliot Hotel . Club Quarters Hotel in Boston . Four Seasons Hotel Boston . Wyndham Boston Beacon Hill . Battery Wharf Hotel, Boston Waterfront . Newbury Guest House . Charlesmark Hotel . Mandarin Oriental, Boston . Courtyard by Marriott Boston Logan Airport . Onyx Hotel - a Kimpton Hotel . The Inn At St Botolph . BEST WESTERN PLUS Roundhouse Suites . Renaissance Boston Waterfront Hotel . Hotel 140 . Next url is /Hotels-g60745-oa60-Boston_Massachusetts-Hotels.html#ACCOM_OVERVIEW\n",
      "Hotel page 3\n",
      "22 hotels\n",
      "Holiday Inn Express Hotel &amp; Suites Boston Garden . Residence Inn Boston Downtown Seaport . The Ritz-Carlton, Boston . The Inn at Longwood Medical . Ames Boston Hotel . BEST WESTERN University Hotel Boston-Brighton . Courtyard Boston-South Boston . Beacon Hill Hotel and Bistro . Hilton Garden Inn Boston Logan Airport . The Godfrey Hotel Boston . The Envoy Hotel, Autograph Collection . Courtyard Boston Downtown . Comfort Inn - Boston . Boston Park Plaza . Aloft Boston Seaport . Element Boston Seaport . The Boston Common Hotel and Conference Center . Milner Hotel . Constitution Inn . Ramada Boston . Days Hotel Boston . Americas Best Value Inn . \n",
      "Reached last page\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code uses identical set of steps from Davide's lecture. The first 2-3 functions are exactly the same.\n",
    "I have added more code to scrape hotel's ratings and Omni Parker reviews. More description below.\n",
    "\n",
    "This code takes huge time (2-2.5 hours) because I couldn't get selenium working properly (explained later). \n",
    "Instead, I've kept the execute output and submitted datafiles to make regression part easier. \n",
    "\n",
    "Implementation details in further comments:\n",
    "\"\"\"\n",
    "from BeautifulSoup import BeautifulSoup\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "import requests\n",
    "import codecs\n",
    "import json\n",
    "import collections\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "\n",
    "base_url = \"http://www.tripadvisor.com\"\n",
    "user_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.76 Safari/537.36\"\n",
    "\n",
    "\"\"\" STEP 1  Get the first page for Boston, MA\"\"\"\n",
    "def get_tourism_page(city, state):\n",
    "    \"\"\" \n",
    "        Return the json containing the\n",
    "        URL of the tourism city page\n",
    "    \"\"\"\n",
    "    url = \"%s/TypeAheadJson?query=%s%%20%s&action=API\" % (base_url, \"%20\".join(city.split()), state)\n",
    "    print \"URL TO REQUEST:\", url\n",
    "    \n",
    "    # Given the url, request the HTML page\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    html = response.text.encode('utf-8')\n",
    "\n",
    "    # Parse json to get url\n",
    "    js = json.loads(html)\n",
    "    results = js['results']\n",
    "    print \"RESULTS: \", results[0]\n",
    "    urls = results[0]['urls'][0]\n",
    "\n",
    "    # get tourism page url\n",
    "    tourism_url = urls['url']\n",
    "    return tourism_url\n",
    "\n",
    "\"\"\" STEP 2  Get url for all hotels in Boston\"\"\"\n",
    "def get_city_page(tourism_url):\n",
    "    \"\"\" \n",
    "        Get the URL of the hotels of the city\n",
    "        using the URL returned by the function\n",
    "        get_tourism_page()\n",
    "    \"\"\"\n",
    "\n",
    "    url = base_url + tourism_url\n",
    "\n",
    "    # Given the url, request the HTML page\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    html = response.text.encode('utf-8')\n",
    "    \n",
    "    soup = BeautifulSoup(html)\n",
    "    li = soup.find(\"li\", {\"class\": \"hotels twoLines\"})\n",
    "    city_url = li.find('a', href = True)\n",
    "    print \"CITY PAGE URL:\", city_url['href']\n",
    "    return city_url['href']\n",
    "\n",
    "\n",
    "\"\"\" STEP 3 return html page for list of Boston hotels\"\"\"\n",
    "def get_hotellist_page(city_url, count):\n",
    "    \"\"\" Get the hotel list page given the url returned by\n",
    "        get_city_page(). Return the html after saving\n",
    "        it to the datadir \n",
    "    \"\"\"\n",
    "    print \"Hotel page\", count\n",
    "    url = base_url + city_url\n",
    "    # Sleep 2 sec before starting a new http request\n",
    "    time.sleep(2)\n",
    "    # Request page\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    html = response.text.encode('utf-8')\n",
    "\n",
    "    return html\n",
    "\n",
    "\"\"\" STEP 4 this is where majority of scraping is done. \n",
    "Check traveler ratings, traveler type in getTravelerRating() and \n",
    "scrape Omni Parker House reviews in scrapeReview()\n",
    "\"\"\"\n",
    "def parse_hotellist_page(html):\n",
    "    \"\"\" \n",
    "    Parse the html pages returned by get_hotellist_page().\n",
    "    Return the next url page to scrape (a city can have\n",
    "    more than one page of hotels) if there is, else exit\n",
    "    the script.\n",
    "    \"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(html)\n",
    "# Extract hotel name, star rating and number of reviews\n",
    "    hotel_boxes = soup.findAll('div', {'class' :'listing easyClear  p13n_imperfect '})\n",
    "    print len(hotel_boxes), \"hotels\"\n",
    "    for hotel_box in hotel_boxes:\n",
    "        name = hotel_box.find('div', {'class' :'listing_title'}).find(text=True)\n",
    "        try:\n",
    "            rating = hotel_box.find('div', {'class' :'listing_rating'})\n",
    "            reviews = rating.find('span', {'class' :'more'}).find(text=True)\n",
    "            stars = hotel_box.find(\"img\", {\"class\" : \"sprite-ratings\"})\n",
    "        except Exception, e:\n",
    "            print \"no ratings for\", name\n",
    "            reviews = \"N/A\"\n",
    "            stars = 'N/A'\n",
    "        hotelref = hotel_box.findAll('a', href= True)\n",
    "        #print \"go to \", hotelref[0]['href'],\" and get traveler ratings\"\n",
    "        \n",
    "        \"\"\"We have a new hotel page. Go to that page and get ratings and dump to file\"\"\"\n",
    "        print name,\n",
    "        ratingfile.write(\"++NEW HOTEL++ %s\\n\" % name)\n",
    "        print '.',\n",
    "        getTraverlerRating(hotelref[0]['href'])\n",
    "        \n",
    "        \n",
    "        if stars != 'N/A':\n",
    "            #log.info(\"Stars: %s\" % stars['alt'].split()[0])\n",
    "            stars = stars['alt'].split()[0]\n",
    "        \n",
    "        \"\"\"Scrape Omni Parker House reviews and store to file\"\"\"\n",
    "        if name == \"Omni Parker House\":\n",
    "            print \"Found Omni Parker House. Scrape reviews\"\n",
    "            print \"HOTEL NAME:\", name\n",
    "            print \"HOTEL REVIEWS: \", reviews\n",
    "            print \"HOTEL STAR RATING:\", stars\n",
    "            omnihrefs = hotel_box.findAll('a', href= True)\n",
    "            for omnihref in omnihrefs:\n",
    "                #print omnihref, \"######\", omnihref['href']\n",
    "                if omnihref.find(text = True) == 'Omni Parker House':\n",
    "                    \n",
    "                    pg = 0\n",
    "                    #print \"DEBUG: Review url is\", omnihref['href']\n",
    "                    print \"page #\", pg,',',\n",
    "                    \"\"\"scrapeReview() returns next url and None if last page\"\"\"\n",
    "                    ret = scrapeReview(omnihref['href'], pg)\n",
    "                    \n",
    "                    while ret:\n",
    "                        pg +=1\n",
    "                        print \"page #\", pg,                         \n",
    "                        ret = scrapeReview(ret, pg)\n",
    "                    print \"Done scraping omni hotel\"\n",
    "\n",
    "                #add this block in main flow to scrape everything\n",
    "                #return\n",
    "\n",
    "# # Get next URL page if exists, else exit\n",
    "    div = soup.find(\"div\", {\"class\" : \"unified pagination standard_pagination\"})\n",
    "    # check if last page\n",
    "    if div.find('span', {'class' : 'nav next ui_button disabled'}):\n",
    "        print \"\\nReached last page\"\n",
    "        return None\n",
    "    \n",
    "    # If it is not las page there must be the Next URL\n",
    "    hrefs = div.findAll('a', href= True)\n",
    "    for href in hrefs:\n",
    "        if href.find(text = True) == 'Next':\n",
    "            print \"Next url is\", href['href']\n",
    "            return href['href']\n",
    "\n",
    "\"\"\"Get Traverler's ratings for every hotel\"\"\"\n",
    "def getTraverlerRating(hotelurl):\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "    response = requests.get(base_url+hotelurl, headers=headers)\n",
    "    #print response\n",
    "    html = response.text.encode('utf-8')   \n",
    "    hotelsoup = BeautifulSoup(html)\n",
    "    \"\"\"Find all ratings from hotel html page and store into file. \n",
    "    Sometimes the values might be missin so safe to use try except\"\"\"\n",
    "    try: \n",
    "        filterbox = hotelsoup.findAll(\"div\",{\"class\":\"with_histogram\"})\n",
    "        ratebox = filterbox[0].findAll(\"div\",{\"class\":\"col rating \"})\n",
    "        ratinglist = ratebox[0].findAll(\"li\")\n",
    "        excel = ratinglist[0].findAll(\"label\",{\"for\":\"taplc_prodp13n_hr_sur_review_filter_controls_0_filterRating_5\"})[0]\n",
    "        ratingfile.write(\"Excellent:%s\\n\" % excel.findAll(\"span\")[2].find(text=True))\n",
    "        #print \"excel\", excel.findAll(\"span\")[2].find(text=True), \n",
    "        vgood = ratinglist[1].findAll(\"label\",{\"for\":\"taplc_prodp13n_hr_sur_review_filter_controls_0_filterRating_4\"})[0]\n",
    "        ratingfile.write(\"Very good: %s\\n\" % vgood.findAll(\"span\")[2].find(text=True))\n",
    "\n",
    "        avg = ratinglist[2].findAll(\"label\",{\"for\":\"taplc_prodp13n_hr_sur_review_filter_controls_0_filterRating_3\"})[0]\n",
    "        ratingfile.write(\"Average:%s\\n\" % avg.findAll(\"span\")[2].find(text=True))\n",
    "\n",
    "        poor = ratinglist[3].findAll(\"label\",{\"for\":\"taplc_prodp13n_hr_sur_review_filter_controls_0_filterRating_2\"})[0]\n",
    "        ratingfile.write(\"Poor:%s\\n\" % poor.findAll(\"span\")[2].find(text=True))\n",
    "\n",
    "        terrible = ratinglist[4].findAll(\"label\",{\"for\":\"taplc_prodp13n_hr_sur_review_filter_controls_0_filterRating_1\"})[0]\n",
    "        ratingfile.write(\"Terrible:%s\\n\" % terrible.findAll(\"span\")[2].find(text=True))\n",
    "\n",
    "        typebox = filterbox[0].findAll(\"div\",{\"class\":\"col segment \"})\n",
    "        typelist = typebox[0].findAll(\"li\")\n",
    "\n",
    "        ratingfile.write(\"Traveler type: \")\n",
    "        #print 'travel'\n",
    "        for t in typelist:\n",
    "            typevallist = t.findAll(\"span\")[1].find(text=True)\n",
    "            #print typevallist,\n",
    "            ratingfile.write(\"%s, \" % typevallist)\n",
    "        ratingfile.write(\"\\n\")\n",
    "        #print \".\"\n",
    "        \n",
    "    except IndexError:\n",
    "        print \"no rating for\", base_url+hotelurl\n",
    "        return\n",
    "    \n",
    "    \n",
    "     \n",
    "    #sys.exit()\n",
    "        \n",
    "\"\"\"STEP 5: Go through each review\"\"\"   \n",
    "\"\"\"\n",
    "Tried to use selenium but didn't work because of overlaying window tripadvisor prompts for every new session\n",
    "The idea is to go on clicking on next review page and parse 6 reviews per http request\n",
    "def scrapeFaster(url):\n",
    "    driver.get(base_url+url)\n",
    "    \n",
    "    pagehtml = driver.page_source\n",
    "    pgsoup = BeautifulSoup(pagehtml)\n",
    "    try:\n",
    "        nexturl = driver.find_element_by_link_text(\"More\")\n",
    "        print \"More BUTTON\", nexturl\n",
    "    except NoSuchElementException:\n",
    "        print \"NO LINK\"\n",
    "        return\n",
    "    nexturl.click() \n",
    "    time.sleep(0.2)\n",
    "    \n",
    "    print \"page loaded\"\n",
    "\"\"\"    \n",
    "\n",
    "\"\"\"\n",
    "Takes reviewurl as input along with pagenum and returns next review page.\n",
    "\n",
    "Goes through all reviews on pgnum, for each review, generates new get() and dumps review ratings to Omni Parker file\n",
    "\"\"\"\n",
    "def scrapeReview(reviewurl, pgnum):\n",
    "    #return\n",
    "    #print base_url+reviewurl\n",
    "    # debug pupose reviewurl = globalurl\n",
    "    debugfile.write(\"\\nscrapeReview: url %s,\" % base_url+reviewurl)\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "    response = requests.get(base_url+reviewurl, headers=headers)\n",
    "    #print response\n",
    "    debugfile.write(\"scrapeReview: response %s\\n\" % response)\n",
    "    html = response.text.encode('utf-8')   \n",
    "    reviewsoup = BeautifulSoup(html) \n",
    "    \n",
    "    revbox = reviewsoup.findAll(\"div\", {\"class\":\"reviewSelector   track_back\"})\n",
    "    olderrevbox = reviewsoup.findAll(\"div\", {\"class\":\"reviewSelector  \"})\n",
    "    oldestbox = reviewsoup.findAll(\"div\", {\"class\":\"reviewSelector  first_aph   track_back\"})\n",
    "    \n",
    "    #if len(olderrevbox):\n",
    "        #print \"older reviews\", len(olderrevbox)\n",
    "    debugfile.write(\"scrapeReview: total reviews to be parsed %s\\n\" % str(len(revbox)+len(olderrevbox)+len(oldestbox)))\n",
    "    print \"(\",len(revbox)+len(olderrevbox)+len(oldestbox),\")|\",\n",
    "    pg = 1\n",
    "    revbox += olderrevbox+oldestbox\n",
    "    \n",
    "    #click on more button and send expanded cells to getstars2 one-by-one\n",
    "    for r in revbox:\n",
    "        reviews = r.findAll('a', href=True)        \n",
    "        for rev in reviews:            \n",
    "            thisrevurl = rev['href']\n",
    "            #print thisrevurl\n",
    "            \n",
    "            #now make http request for review url and write values to a file\n",
    "            getStars2(thisrevurl)\n",
    "            \n",
    "    nextpages = reviewsoup.findAll(\"a\", {\"class\":\"pageNum taLnk\"})\n",
    "    pgnum = min(pgnum,4)\n",
    "    try:\n",
    "        #print \"\\nnext page?\", nextpages[pgnum]['href']\n",
    "        debugfile.write(\"scrapeReview: next page url %s\\n\" % nextpages[pgnum]['href'])\n",
    "        return nextpages[pgnum]['href']\n",
    "    except IndexError:\n",
    "        print \"Done with all pages\", pgnum\n",
    "        return None\n",
    "\n",
    "\"\"\"STEP 6 : Access individual review, parse ratings and store in a file\n",
    "This is the bottleneck function. Every review generates on get() causing huge delays\"\"\"\n",
    "\n",
    "def getStars2(revurl):\n",
    "    #print base_url+revurl,\n",
    "    debugfile.write(\"getStars2: url %s,\" % base_url+revurl)\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "    response = requests.get(base_url+revurl, headers=headers)\n",
    "    #print response\n",
    "    debugfile.write(\"getStars2: response %s\\n\" % response)\n",
    "    html = response.text.encode('utf-8') \n",
    "    \n",
    "    reviewsoup = BeautifulSoup(html)\n",
    "    reviewblock = reviewsoup.findAll(\"div\",{\"class\":\"deckC\"})\n",
    "    try:\n",
    "        reviewlist = reviewblock[0].findAll(\"div\",{\"class\":\"  reviewSelector \"})\n",
    "    except IndexError:\n",
    "        return\n",
    "    review = reviewlist[0]\n",
    "                \n",
    "    #print review\n",
    "    \"\"\"Get the review id from review tab\"\"\"\n",
    "    id = review['id']\n",
    "    #print id, \n",
    "    debugfile.write(\"getStars2: id: %s\\t\" % id)\n",
    "    ratelist = review.findAll(\"div\", {\"class\":\"rating-list\"})\n",
    "    #print ratelist\n",
    "    \n",
    "    \"\"\"Only consider first review in the list. This could be optimized since a review page has 6 more ratings.\n",
    "    But it'll need additional logic to track scraped reviews to avoid duplicate scraping\"\"\"\n",
    "    try:\n",
    "        stars = ratelist[0].findAll(\"li\",{\"class\":\"recommend-answer\"})\n",
    "    except IndexError:\n",
    "        return\n",
    "\n",
    "    \"\"\"Access rating attribute and value and dump to file\"\"\"\n",
    "    for val in stars:\n",
    "        v = val.findAll(\"img\")\n",
    "        k = val.findAll(\"div\",{\"class\":\"recommend-description\"})\n",
    "\n",
    "        try:\n",
    "            access = k[0],v[0]\n",
    "        except IndexError:\n",
    "            continue\n",
    "        omnifile.write(\"%s:\" % id)\n",
    "        omnifile.write(\"%s:\" % k[0].find(text=True))\n",
    "        omnifile.write(\"%s\\n\" % v[0]['alt'][0])\n",
    "\n",
    "\"\"\"\n",
    "#This is a try using selenium. Couldn't get this to work correctly - next page not loading\n",
    "def getStars(revurl, pg):\n",
    "    print base_url+revurl\n",
    "    driver.get(base_url+revurl)\n",
    "    print \"page #\", pg\n",
    "    #time.sleep(1)\n",
    "    while True:\n",
    "        #geturl = base_url+revurl\n",
    "        #headers = { 'User-Agent' : user_agent }\n",
    "        #response = requests.get(base_url+revurl, headers=headers)\n",
    "        #print response\n",
    "        #html = response.text.encode('utf-8')   \n",
    "        \n",
    "        html = driver.page_source\n",
    "        reviewsoup = BeautifulSoup(html) \n",
    "        reviewblock = reviewsoup.findAll(\"div\",{\"class\":\"deckC\"})\n",
    "        reviewlist = reviewblock[0].findAll(\"div\",{\"class\":\"  reviewSelector \"})\n",
    "        #print reviewlist\n",
    "\n",
    "        revnum = 0\n",
    "        for review in reviewlist:        \n",
    "            \n",
    "            if pg and not revnum:\n",
    "                revnum += 1\n",
    "                continue\n",
    "            \n",
    "            #print review\n",
    "            id = review['id']\n",
    "            print id\n",
    "            ratelist = review.findAll(\"div\", {\"class\":\"rating-list\"})\n",
    "            #print ratelist\n",
    "            for i in xrange(len(ratelist)):\n",
    "\n",
    "                stars = ratelist[i].findAll(\"li\",{\"class\":\"recommend-answer\"})\n",
    "                #inside stars, access sprite and description and write\n",
    "                #print stars\n",
    "                #ratedict = collections.defaultdict(list)\n",
    "                for val in stars:\n",
    "                    v = val.findAll(\"img\")\n",
    "                    k = val.findAll(\"div\",{\"class\":\"recommend-description\"})\n",
    "                    #print k,v\n",
    "                    #print id, \":\",k[0].find(text=True),\":\", v[0]['alt'][0]\n",
    "                    #ratedict[k[0].find(text=True)] = v[0]['alt'][0]\n",
    "\n",
    "                    #omnifile.write(\"%s:\" % id)\n",
    "                    #omnifile.write(\"%s:\" % k[0].find(text=True))\n",
    "                    #omnifile.write(\"%s\\n\" % v[0]['alt'][0])\n",
    "            revnum += 1\n",
    "            \n",
    "        pg += 1\n",
    "        try:\n",
    "            nexturl = driver.find_element_by_link_text(\"Next\")\n",
    "            print \"NEXT BUTTON\", nexturl\n",
    "        except NoSuchElementException:\n",
    "            print \"NO LINK\"\n",
    "            break\n",
    "        nexturl.click() \n",
    "        body = driver.find_element_by_tag_name(\"body\")\n",
    "        body.send_keys(Keys.CONTROL + 't')\n",
    "        def link_has_gone_stale():\n",
    "            try:\n",
    "                # poll the link with an arbitrary call\n",
    "                nexturl.find_elements_by_id('doesnt-matter') \n",
    "                return False\n",
    "            except StaleElementReferenceException:\n",
    "                return True\n",
    "        time.sleep(1)\n",
    "        wait_for(link_has_gone_stale)\n",
    "        \n",
    "        nextpage = reviewsoup.findAll(\"a\",{\"class\":\"pageNum taLnk\"})\n",
    "        print \"go to next\", nextpage[0]['href']\n",
    "        revurl = nextpage[0]['href']\n",
    "    #return nextpage[0]['href']\n",
    "    #return nextpage[0]['href']\n",
    "    #omnidict[id] = ratedict\n",
    "    #print id,\":\",k,\":\", v\n",
    "    #print stars\n",
    "def wait_for(condition_function):\n",
    "    start_time = time.time()\n",
    "    while time.time() < start_time + 10:\n",
    "        if condition_function():\n",
    "            return True\n",
    "        else:\n",
    "            time.sleep(0.1)\n",
    "    raise Exception(\n",
    "        'Timeout waiting for {}'.format(condition_function.__name__)\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "#globalurl = \"/Hotel_Review-g60745-d89599-Reviews-or5270-Omni_Parker_House-Boston_Massachusetts.html#REVIEWS\"\n",
    "print 'get url'\n",
    "\n",
    "\"\"\"\n",
    "Just to be safe, adding NEWFILE to filename to avoid replacing the original complete file\n",
    "\"\"\"\n",
    "omnifile = open(\"omni-scrapte-out-NEWFILE.dat\",\"w\")\n",
    "ratingfile = open(\"travel-rating.dat-NEWFILE\",\"w\")\n",
    "debugfile = open(\"debug.log\",\"w\")\n",
    "tourism_url = get_tourism_page('boston', 'massachusetts')\n",
    "#Get URL to obtaint the list of hotels in a specific city\n",
    "city_url = get_city_page(tourism_url)\n",
    "c=0\n",
    "#driver = webdriver.Firefox()\n",
    "#driver.wait = WebDriverWait(driver, 5)\n",
    "while(True):\n",
    "    c +=1\n",
    "    \"\"\"Get first page of hotels in boston\"\"\"\n",
    "    html = get_hotellist_page(city_url,c)\n",
    "    \n",
    "    \"\"\"Invoke scraping for each hotel\"\"\"\n",
    "    city_url = parse_hotellist_page(html)\n",
    "    if not city_url:\n",
    "        break\n",
    "#close all files        \n",
    "omnifile.close()\n",
    "ratingfile.close()\n",
    "debugfile.close()\n",
    "#driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Task 2 (20 pts) **\n",
    "\n",
    "Now, we will use regression to analyze this information. First, we will fit a linear regression model that predicts the average rating. For example, for the hotel above, the average rating is\n",
    "\n",
    "$$ \\text{AVG_SCORE} = \\frac{1*31 + 2*33 + 3*98 + 4*504 + 5*1861}{2527}$$\n",
    "\n",
    "Use the model to analyze the important factors that decide the $\\text{AVG_SCORE}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 ratings added to omnidict\n",
      "82 hotels added to dict\n",
      "Hilton Boston Downtown / Faneuil Hall missing Location\n",
      "Hilton Boston Downtown / Faneuil Hall missing Sleep Quality\n",
      "Hilton Boston Downtown / Faneuil Hall missing Rooms\n",
      "Hilton Boston Downtown / Faneuil Hall missing Service\n",
      "Hilton Boston Downtown / Faneuil Hall missing Value\n",
      "Hilton Boston Downtown / Faneuil Hall missing Cleanliness\n",
      "Residence Inn Boston Back Bay / Fenway missing Location\n",
      "Residence Inn Boston Back Bay / Fenway missing Sleep Quality\n",
      "Residence Inn Boston Back Bay / Fenway missing Rooms\n",
      "Residence Inn Boston Back Bay / Fenway missing Service\n",
      "Residence Inn Boston Back Bay / Fenway missing Value\n",
      "Residence Inn Boston Back Bay / Fenway missing Cleanliness\n",
      "Element Boston Seaport missing Location\n",
      "Generated 82 lists for all hotels\n",
      "Now feed all these 82 vectors to fit a model\n",
      "(82, 17)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               Avgscore   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 4.849e+29\n",
      "Date:                Tue, 29 Mar 2016   Prob (F-statistic):               0.00\n",
      "Time:                        08:28:57   Log-Likelihood:                 1918.2\n",
      "No. Observations:                  81   AIC:                            -3802.\n",
      "Df Residuals:                      64   BIC:                            -3762.\n",
      "Df Model:                          16                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept     4.547e-13   1.03e-11      0.044      0.965     -2.02e-11  2.11e-11\n",
      "Excellent        5.0000   5.51e-14   9.08e+13      0.000         5.000     5.000\n",
      "Verygood         4.0000   5.57e-14   7.18e+13      0.000         4.000     4.000\n",
      "Average          3.0000   9.99e-14      3e+13      0.000         3.000     3.000\n",
      "Poor             2.0000   1.62e-13   1.23e+13      0.000         2.000     2.000\n",
      "Terrible         1.0000    1.5e-13   6.68e+12      0.000         1.000     1.000\n",
      "Families      4.263e-14   6.56e-14      0.650      0.518     -8.84e-14  1.74e-13\n",
      "Couples       7.105e-15   6.45e-14      0.110      0.913     -1.22e-13  1.36e-13\n",
      "Solo          1.776e-14   7.76e-14      0.229      0.820     -1.37e-13  1.73e-13\n",
      "Business      8.882e-15    5.7e-14      0.156      0.877     -1.05e-13  1.23e-13\n",
      "Friends       4.974e-14   7.51e-14      0.662      0.510        -1e-13     2e-13\n",
      "Location     -1.137e-13    3.3e-12     -0.034      0.973     -6.71e-12  6.48e-12\n",
      "SleepQuality  1.592e-12   1.46e-11      0.109      0.914     -2.77e-11  3.08e-11\n",
      "Rooms        -1.819e-12   1.28e-11     -0.142      0.888     -2.74e-11  2.38e-11\n",
      "Service      -9.095e-13   1.73e-11     -0.052      0.958     -3.55e-11  3.37e-11\n",
      "Value                 0   1.18e-11          0      1.000     -2.36e-11  2.36e-11\n",
      "Cleanliness   2.728e-12   1.92e-11      0.142      0.887     -3.55e-11   4.1e-11\n",
      "==============================================================================\n",
      "Omnibus:                       49.980   Durbin-Watson:                   1.181\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              586.992\n",
      "Skew:                           1.392   Prob(JB):                    3.44e-128\n",
      "Kurtosis:                      15.891   Cond. No.                     1.98e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.98e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "Created (82, 16) (82,)\n",
      "0    16917\n",
      "1    11260\n",
      "2    10316\n",
      "3    13567\n",
      "4     2267\n",
      "Name: Avgscore, dtype: int64\n",
      "[('Excellent', 4.9999999999999991), ('Verygood', 3.9999999999999987), ('Average', 3.000000000000008), ('Poor', 2.0000000000000018), ('Terrible', 0.99999999999998246), ('Families', -1.236694878909716e-15), ('Couples', 1.0340601919552109e-15), ('Solo', -1.9867141455488598e-15), ('Business', 4.7527248033094344e-15), ('Friends', -2.9009221316004996e-15), ('Location', -3.4594051510633637e-14), ('SleepQuality', -3.6970641901592892e-13), ('Rooms', -2.7733688218144397e-13), ('Service', 7.0677670784475804e-13), ('Value', 2.4642311305434889e-13), ('Cleanliness', -2.6105190699505751e-13)]\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import time, math\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import scipy as sp\n",
    "import scipy.sparse.linalg as linalg\n",
    "import scipy.cluster.hierarchy as hr\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "import sklearn.datasets as datasets\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.utils as utils\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.cross_validation as cross_validation\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from patsy import dmatrices\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pprint\n",
    "\n",
    "def mergeOmnifile():\n",
    "    with open(\"omni-scrapte-out.dat\") as omnifile:\n",
    "        lines = omnifile.readlines()\n",
    "        for line in lines:\n",
    "            #print line.split(\":\")[1],\":\", int(line.split(\":\")[2].split(\"\\n\")[0])\n",
    "            splitline = line.split(\":\")\n",
    "            k1,k2 = splitline[1], splitline[2][:-1] \n",
    "                    \n",
    "            if k2 not in omnidict[k1]:\n",
    "                omnidict[k1][k2] = 0\n",
    "            omnidict[k1][k2] += 1                \n",
    "    \n",
    "    omnifile.close()\n",
    "\n",
    "def parseDatafiles():\n",
    "    \n",
    "    newlist = [0]\n",
    "    i = 0\n",
    "    with open(\"travel-rating.dat\") as tratefile:\n",
    "        lines = tratefile.readlines()     \n",
    "        hotelname = None\n",
    "        for line in lines:            \n",
    "            if line[0] == '+':   \n",
    "                if hotelname:\n",
    "                    #print allratedict[hotelname]\n",
    "                    for attr in attrlist:\n",
    "                        try:\n",
    "                            newlist.append(allratedict[hotelname][attr])\n",
    "                        except KeyError:\n",
    "                            print hotelname, \"missing\", attr\n",
    "                            newlist.append(0)\n",
    "                    #print newlist, len(newlist)\n",
    "                    hoteldict[hotelname] = newlist\n",
    "                    #print len(hoteldict), hotelname, i\n",
    "                i+=1\n",
    "                hotelname = line.split('+')[4][1:-1]\n",
    "                #print hotelname\n",
    "                newlist = [0]\n",
    "                avgscore = 0\n",
    "            else:\n",
    "                if line.split(\":\")[0] == \"Traveler type\":\n",
    "                    typelist = line.split(\":\")[1].split(\")\")\n",
    "                    for ttype in typelist:\n",
    "                        try:\n",
    "                            val = int(ttype.split(\"(\")[1].replace(',',''))\n",
    "                            #print val\n",
    "                            newlist.append(int(val))\n",
    "                        except IndexError:\n",
    "                            continue\n",
    "                    newlist[0] = avgscore\n",
    "                else:\n",
    "                    key = line.split(\":\")[0]\n",
    "                    val = int(line.split(\":\")[1][:-1].replace(',',''))\n",
    "                    #print key, val\n",
    "                    newlist.append(int(val))\n",
    "                    avgscore += val*avgscoredict[key]\n",
    "    if hotelname:\n",
    "        hoteldict[hotelname] = newlist\n",
    "        \n",
    "    tratefile.close()\n",
    "\n",
    "def parseRateDat():        \n",
    "    with open(\"rating-summary.dat\") as ratefile:\n",
    "        hotelratings = ratefile.readlines()\n",
    "        prevhname = None\n",
    "        newdict = collections.defaultdict(dict)\n",
    "        for line in hotelratings:\n",
    "            splitline = line.split(\":\")\n",
    "            hotelname = splitline[0]\n",
    "            if hotelname != prevhname:\n",
    "\n",
    "                appendDict(newdict, prevhname)\n",
    "                \n",
    "                prevhname = hotelname\n",
    "                #print \"###NEW###\", hotelname\n",
    "                newdict = collections.defaultdict(dict)                                \n",
    "                \n",
    "            k1,k2,v = splitline[1], splitline[2], splitline[3][:-1]\n",
    "            #print k1,k2,v\n",
    "            newdict[k1][k2] = int(v)\n",
    "        \n",
    "    appendDict(newdict, prevhname)\n",
    "    appendDict(omnidict, \"Omni Parker House\")\n",
    "    #print omnidict\n",
    "            \n",
    "    ratefile.close()\n",
    "    #print len(hoteldict)\n",
    "\n",
    "def appendDict(newdict, prevhname):\n",
    "    for k1 in newdict.keys():\n",
    "        #print k1,newdict[k1]\n",
    "        if k1 not in attrlist:\n",
    "            #print k1\n",
    "            continue\n",
    "        ratesum = 0\n",
    "        totalnum = 0\n",
    "        for k2 in newdict[k1].keys():\n",
    "\n",
    "            ratesum += int(k2)*int(newdict[k1][k2])\n",
    "            totalnum += int(newdict[k1][k2])\n",
    "        #print prevhname, k1, 1.0*ratesum/totalnum\n",
    "        score = 1.0*ratesum/totalnum\n",
    "        allratedict[prevhname][k1] = score #math.ceil(score) if (math.ceil(score)- score <0.5) else int(score) \n",
    "        #allratedict[prevhname][k1] = ratesum\n",
    "        \n",
    "attrlist = ['Location', 'Sleep Quality', 'Rooms', 'Service', 'Value', 'Cleanliness']\n",
    "avgscoredict = {\"Excellent\":5, \"Very good\":4, \"Average\":3, \"Poor\":2, \"Terrible\":1}    \n",
    "omnidict = collections.defaultdict(dict)\n",
    "#  1 avg rating, 5 traveler ratings, 5 traveler types, 6 rating attributes,\n",
    "allratedict = collections.defaultdict(dict)\n",
    "hoteldict = collections.defaultdict(list)\n",
    "\n",
    "\n",
    "mergeOmnifile()    \n",
    "print len(omnidict), \"ratings added to omnidict\"\n",
    "\n",
    "\n",
    "parseRateDat()\n",
    "print len(allratedict), \"hotels added to dict\"\n",
    "\n",
    "\n",
    "parseDatafiles()\n",
    "print \"Generated\", len(hoteldict), \"lists for all hotels\"\n",
    "print \"Now feed all these\", len(hoteldict), \"vectors to fit a model\"\n",
    "rate_vector = []\n",
    "avg_vector = []\n",
    "\n",
    "X = pd.DataFrame(v for v in hoteldict.values())\n",
    "print X.shape\n",
    "X.columns = ['Avgscore', 'Excellent', 'Verygood', 'Average', 'Poor', 'Terrible', 'Families', 'Couples', 'Solo', 'Business','Friends', 'Location', 'SleepQuality', 'Rooms', 'Service', 'Value', 'Cleanliness']\n",
    "\n",
    "#print X.head()\n",
    "\n",
    "lm = smf.ols(formula='Avgscore ~ Excellent + Verygood + Average + Poor + Terrible + Families + Couples + Solo + Business + Friends + Location + SleepQuality + Rooms + Service + Value + Cleanliness', data=X).fit()\n",
    "#lm = smf.ols(formula='Avgscore ~ Value + Location + Service + Excellent + Verygood + Average', data=X).fit()\n",
    "print lm.summary()\n",
    "data = X.fillna(0)\n",
    "\n",
    "\n",
    "# create X and y\n",
    "feature_cols = ['Excellent', 'Verygood', 'Average', 'Poor', 'Terrible', 'Families', 'Couples', 'Solo', 'Business','Friends', 'Location', 'SleepQuality', 'Rooms', 'Service', 'Value', 'Cleanliness']\n",
    "X = data[feature_cols]\n",
    "y = data.Avgscore\n",
    "\n",
    "print \"Created\", X.shape, y.shape\n",
    "print y.head()\n",
    "#print X,y\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X, y)\n",
    "\n",
    "# print coefficients\n",
    "print zip(feature_cols, lm.coef_)\n",
    "\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Task 3 (30 pts) **\n",
    "\n",
    "Finally, we will use logistic regression to decide if a hotel is _excellent_ or not. We classify a hotel as _excellent_ if more than **60%** of its ratings are 5 stars. This is a binary attribute on which we can fit a logistic regression model. As before, use the model to analyze the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Use the same datastructured parsed in previous part:_ Please execute previous cell before proceeding (one takes a second or two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 hotels added true/false\n",
      "(82, 1)\n",
      "  isExcellent\n",
      "0        True\n",
      "1        True\n",
      "2       False\n",
      "3       False\n",
      "4        True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.582810\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            isExcellent   No. Observations:                   82\n",
      "Model:                          Logit   Df Residuals:                       66\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Tue, 29 Mar 2016   Pseudo R-squ.:                  0.1125\n",
      "Time:                        08:29:05   Log-Likelihood:                -47.790\n",
      "converged:                       True   LL-Null:                       -53.850\n",
      "                                        LLR p-value:                    0.6699\n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "--------------------------------------------------------------------------------\n",
      "Excellent       -0.0070      0.009     -0.776      0.438        -0.025     0.011\n",
      "Verygood        -0.0155      0.010     -1.618      0.106        -0.034     0.003\n",
      "Average          0.0105      0.016      0.648      0.517        -0.021     0.042\n",
      "Poor            -0.0217      0.026     -0.839      0.402        -0.072     0.029\n",
      "Terrible        -0.0040      0.024     -0.165      0.869        -0.051     0.043\n",
      "Families         0.0086      0.011      0.803      0.422        -0.012     0.030\n",
      "Couples          0.0123      0.011      1.145      0.252        -0.009     0.033\n",
      "Solo            -0.0084      0.013     -0.656      0.512        -0.034     0.017\n",
      "Business         0.0088      0.009      0.935      0.350        -0.010     0.027\n",
      "Friends          0.0051      0.012      0.411      0.681        -0.019     0.030\n",
      "Location         0.7046      0.641      1.100      0.272        -0.551     1.961\n",
      "SleepQuality    -2.8488      2.450     -1.163      0.245        -7.651     1.954\n",
      "Rooms           -2.2269      2.206     -1.009      0.313        -6.551     2.097\n",
      "Service         -0.3611      2.761     -0.131      0.896        -5.773     5.050\n",
      "Value            0.2133      1.881      0.113      0.910        -3.474     3.900\n",
      "Cleanliness      4.2417      3.257      1.302      0.193        -2.142    10.625\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def parseExcellent():        \n",
    "    with open(\"rating-summary.dat\") as ratefile:\n",
    "        hotelratings = ratefile.readlines()\n",
    "        prevhname = None\n",
    "        newdict = collections.defaultdict(dict)\n",
    "        for line in hotelratings:\n",
    "            splitline = line.split(\":\")\n",
    "            hotelname = splitline[0]\n",
    "            if hotelname != prevhname:\n",
    "\n",
    "                appendExcel(newdict, prevhname)\n",
    "                \n",
    "                prevhname = hotelname\n",
    "                #print \"###NEW###\", hotelname\n",
    "                newdict = collections.defaultdict(dict)                                \n",
    "                \n",
    "            k1,k2,v = splitline[1], splitline[2], splitline[3][:-1]\n",
    "            #print k1,k2,v\n",
    "            newdict[k1][k2] = int(v)\n",
    "        \n",
    "    appendExcel(newdict, prevhname)\n",
    "    appendExcel(omnidict, \"Omni Parker House\")\n",
    "    #print omnidict\n",
    "            \n",
    "    ratefile.close()\n",
    "    #print len(hoteldict)\n",
    "\n",
    "def appendExcel(d, n):\n",
    "    totalrev = 0\n",
    "    maxstar = 0\n",
    "    for k1 in d.keys():\n",
    "        \n",
    "        for k2 in d[k1].keys():\n",
    "            if k2 == '5':\n",
    "                maxstar +=d[k1][k2]\n",
    "            totalrev+=d[k1][k2]\n",
    "    if totalrev == 0:\n",
    "        #print n, \"000000000\"\n",
    "        return\n",
    "    #print n, 1.0*maxstar/totalrev >= 0.6\n",
    "    exceldict[n] = 1.0*maxstar/totalrev >= 0.6\n",
    "        \n",
    "exceldict = collections.defaultdict()\n",
    "parseExcellent()\n",
    "print len(exceldict), \"hotels added true/false\"\n",
    "\n",
    "y = pd.DataFrame(v for v in exceldict.values())\n",
    "print y.shape\n",
    "y.columns = ['isExcellent']\n",
    "print y.head()\n",
    "\n",
    "excelfit = sm.Logit(y, X[feature_cols])\n",
    " \n",
    "# fit the model\n",
    "result = excelfit.fit() \n",
    "print result.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code for setting the style of the notebook\n",
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"../../theme/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
