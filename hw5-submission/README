Task 1:
Two stage MapReduce:

copy com-youtube.ungraph.txt to hdfs

hadoop jar hadoop-streaming-2.6.0.jar -file mapper1.py -file reducer1.py -mapper mapper1.py -reducer reducer1.py
-combiner reducer1.py -input com-youtube.ungraph.txt -output part1trianglecount

hadoop jar hadoop-streaming-2.6.0.jar -file mapper2.py -file reducer2.py -mapper mapper2.py -reducer reducer2.py
-combiner reducer2.py -input part1trialnglecount -output trianglecount

output in hdfs file trianglecount


Task 2:
Run spark recommendation code with other input files for ratings and prediction pairs in required formats.

Not attempted task 3.
