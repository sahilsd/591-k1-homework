{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpful Prediction:\n",
    "\n",
    "    While looking at various methods for 1st task, I came across decision tree classifiers in scikit - http://scikit-learn.org/stable/modules/tree.html.\n",
    "    These types of classifiers are useful for predicting multi-value attributes. If we can estimate prediction percentage and multiply it with total reviews, we can predict nHelpful for a given pair. The problem with using standard regression model is infinitely many number of possible real values in [0,1]. \n",
    "    \n",
    "    A very naive way to solve this kind of problem is to build n independent models, i.e. one for each output, and then to use those models to independently predict each one of the n outputs. However, because it is likely that the output values related to the same input are themselves correlated, an often better way is to build a single model capable of predicting simultaneously all n outputs. First, it requires lower training time since only a single estimator is built. Second, the generalization accuracy of the resulting estimator may often be increased.\n",
    "    Therefore decision trees give a very good alternative to fit a multi-value data and predict helpful percentage for a user-item pair.\n",
    "   \n",
    "     To effectively use this model, I tried to do sentiment analysis using vaderSentiment which proves to be very time consuming. Instead I've used wordcounting analyzer called textstat available at https://pypi.python.org/pypi/textstat/0.1.4 (#pip install textstat). This gives the number of relevent words in the review and we can estimate how good the review might be. This will obviously work better if we can get an actual score using vaderSentiment but it was a tradeoff I chose. \n",
    "     \n",
    "     Then using these vectors, we need to decide what the tree should look like. Decision Tree classifier has various parameters like number of leaf nodes, max depth of a tree and so on. Since these are the two fundamental values required by the model, I've tried to find good enough values using two nested for loops for leaf nodes and depth.\n",
    "     \n",
    "     Using the wordcounts as a reference to how good the review might be, we can build our model based on ewview rating. Using this model, we can then train each leaf predictor from training dataset. This trained model is then ready to be used to predict percentage nHelpful reviews. Multiplying this by 'outOf' field gives actual count of helpful reviews.\n",
    "   \n",
    "       There are few interesting pros and cons listed on scikit manual:\n",
    "    The cost of using the tree (i.e., predicting data) is logarithmic in the number of data points used to train the tree.\n",
    "    Able to handle both numerical and categorical data. Other techniques are usually specialised in analysing datasets that have only one type of variable. See algorithms for more information.\n",
    "    Able to handle multi-output problems. \n",
    "    Performs well even if its assumptions are somewhat violated by the true model from which the data were generated.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy\n",
    "import scipy.optimize\n",
    "\n",
    "from sklearn.ensemble.forest import DecisionTreeRegressor as tree\n",
    "from textstat.textstat import textstat\n",
    "import string\n",
    "import random\n",
    "#from vaderSentiment.vaderSentiment import sentiment as vaderSentiment\n",
    "#from vaderSentiment import sentiment as vaderSentiment \n",
    "from nltk.stem import PorterStemmer as ps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def readJson(f):\n",
    "  for l in open(f):\n",
    "    yield eval(l)\n",
    "    \n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.810134030999\n"
     ]
    }
   ],
   "source": [
    "#same as baseline - parse data\n",
    "allHelpful = []\n",
    "userRate = {}\n",
    "userHelpful = defaultdict(list)\n",
    "data = []\n",
    "for l in readJson(\"train.json\"):\n",
    "    data.append(l)\n",
    "    user,item = l['reviewerID'],l['asin']\n",
    "    allHelpful.append(l['helpful'])\n",
    "    userHelpful[user].append(l['helpful'])\n",
    "\n",
    "ratingAvg = sum([x['nHelpful'] for x in allHelpful]) * 1.0 / sum([x['outOf'] for x in allHelpful])\n",
    "\n",
    "for u in userHelpful:\n",
    "    totalU = sum([x['outOf'] for x in userHelpful[u]])\n",
    "    if totalU > 0:\n",
    "        userRate[u] = sum([x['nHelpful'] for x in userHelpful[u]]) * 1.0 / totalU\n",
    "    else:\n",
    "        userRate[u] = ratingAvg\n",
    "print ratingAvg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "Xytest = []\n",
    "\n",
    "for l in data[900000:]:\n",
    "    Xytest.append(l)\n",
    "    \n",
    "print len(Xytest)\n",
    "random.shuffle(Xytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill training data\n",
    "Takes some time to go through all the reviews and generate vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7272727272727273, 2.0, 159, 2, 0.16352201257861634] 1.0\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "stemmer = ps()\n",
    "for l in data[:900000]:\n",
    "    userid, itemid = l['reviewerID'], l['asin']\n",
    "    review,summary = l['reviewText'], l['summary']\n",
    "    rating,helpful = l['overall'], l['helpful']\n",
    "    \n",
    "    userAvgRate = ratingAvg if userid not in userRate else userRate[userid]\n",
    "    review = stemmer.stem(review.lower()) if review else ''\n",
    "    assert review is not None\n",
    "    \n",
    "    reviewCount = textstat.lexicon_count(review)\n",
    "    summaryCount = textstat.lexicon_count(summary)\n",
    "    \n",
    "    #vader is too slow\n",
    "    #reviewvs = vaderSentiment(review) \n",
    "    #summaryvs = vaderSentiment(summary)    \n",
    "    #reviewscore = (-reviewvs['neg']+reviewvs['pos'])*5\n",
    "    #summaryscore = (-summaryvs['neg']+summaryvs['pos'])*5\n",
    "\n",
    "    if not reviewCount:\n",
    "        punct = 0 \n",
    "    else:\n",
    "        punct = (1.0*sum([c in string.punctuation for c in review]))/reviewCount\n",
    "        \n",
    "    X.append([userAvgRate, rating, reviewCount, summaryCount, punct])\n",
    "    if helpful['outOf']==0 or helpful['nHelpful'] == 0:\n",
    "        y.append(userAvgRate)\n",
    "    else:\n",
    "        y.append((helpful['nHelpful']*1.0)/helpful['outOf'])\n",
    "print X[0], y[0]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XTree = []\n",
    "for x in X:\n",
    "    #3.88 is the global avg from task1\n",
    "    x = [x[0], round(x[1]/3.88, 2), x[2], x[3], x[4]]\n",
    "    XTree.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    This is another approach for same algorithm but RandomForest gives worse predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.ensemble.forest import RandomForestRegressor\\nRF = RandomForestRegressor(n_estimators = 5)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from sklearn.ensemble.forest import RandomForestRegressor\n",
    "RF = RandomForestRegressor(n_estimators = 5)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X = np.array(X)\\ny = np.array(y)\\nRF.fit(X, y)\\nyPred = RF.predict(X)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"X = np.array(X)\n",
    "y = np.array(y)\n",
    "RF.fit(X, y)\n",
    "yPred = RF.predict(X)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before training error, find optimal tree size - \n",
    "    (not exactly sure to what extent this affects predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leaf 27 None 0.0\n",
      "0.682503844284\n",
      "leaf 28 27 0.624499473423\n",
      "0.682503844284\n",
      "leaf 29 28 0.62347196651\n",
      "0.682503844284\n",
      "leaf 30 28 0.626219810311\n",
      "0.682503844284\n",
      "leaf 31 30 0.627378435183\n",
      "0.682503844284\n",
      "leaf 32 30 0.626012148483\n",
      "0.682503844284\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "\n",
    "glerr = float('inf')\n",
    "optLeaf, optDepth = None, None\n",
    "rate = 0.0\n",
    "\n",
    "for leaf in xrange(27, 33):\n",
    "    print 'leaf', leaf, optLeaf, rate\n",
    "    \"\"\"\n",
    "    Predict with each model and find minimum error parameters\n",
    "    \"\"\"\n",
    "    for depth in range(5, 16, 2):\n",
    "        model = tree(min_samples_leaf=leaf, max_depth=depth)\n",
    "        model = model.fit(XTree,y)\n",
    "\n",
    "        err = 0\n",
    "        for l in Xytest[:10000]:            \n",
    "            user,item,review,rating,helpful,summary= l['reviewerID'],l['asin'],l['reviewText'],l['overall'],l['helpful'],l['summary']\n",
    "            if user not in userRate:\n",
    "                uPred = ratingAvg  \n",
    "            else:\n",
    "                uPred = userRate[user]\n",
    "            review = review if review else ''\n",
    "            reviewc = textstat.lexicon_count(review)\n",
    "            summaryc = textstat.lexicon_count(summary)\n",
    "            punctR = 0 if not reviewc else (1.0*sum([c in string.punctuation for c in review]))/reviewc\n",
    "\n",
    "            x = [uPred,  round(rating/3.88,2), reviewc, summaryc, punctR]\n",
    "            pred = model.predict(x)[0]\n",
    "            #pred = RF.predict(x)\n",
    "            pred = l['helpful']['outOf'] * pred\n",
    "            err += abs(pred-l['helpful']['nHelpful'])\n",
    "\n",
    "        rate = 1.0*err/10000\n",
    "        if rate < glerr:\n",
    "            glerr = rate\n",
    "            \"\"\"\n",
    "            Later use these to build predicting model:\n",
    "            \"\"\"\n",
    "            optLeaf, optDepth  = leaf, depth\n",
    "        \n",
    "    print merror\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 5\n"
     ]
    }
   ],
   "source": [
    "print optLeaf, optDepth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Create model with parameters found above\n",
    "    The best results I've seen so far are with leaf=29, depth=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model = tree(min_samples_leaf=optLeaf, max_depth=optDepth)\n",
    "model = tree(min_samples_leaf=29, max_depth=12)\n",
    "model = model.fit(XTree,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs = open(\"pairs_Helpful.txt\").readlines()\n",
    "\n",
    "predfile = open(\"secMypredictions_Helpful.txt\", 'w')\n",
    "predfile.write(pairs[0])\n",
    "\n",
    "index=0\n",
    "for l in readJson(\"helpful.json\"):\n",
    "    index += 1\n",
    "    \n",
    "    user,item,= l['reviewerID'],l['asin'] \n",
    "    review,rating = l['reviewText'],l['overall']\n",
    "    helpful,summary = l['outOf'],l['summary']\n",
    "    \n",
    "    userPred = ratingAvg if user not in userRate else userRate[user]\n",
    "    review = review if review else ''\n",
    "    assert review is not None\n",
    "    \n",
    "    reviewcnt = textstat.lexicon_count(review)\n",
    "    summarycnt = textstat.lexicon_count(summary)\n",
    "    if not reviewcnt:\n",
    "        punctR = 0  \n",
    "    else:\n",
    "        punctR = (1.0*sum([c in string.punctuation for c in review]))/reviewcnt\n",
    "    \n",
    "    x = [userPred, rating, reviewcnt, summarycnt, punctR]    \n",
    "    prediction = model.predict(x)\n",
    "    #prediction = RF.predict(x)    \n",
    "    u,i,outOf = pairs[index].strip().split('-')\n",
    "    outOf = int(outOf)    \n",
    "    #print u,i,outOf, prediction[0]\n",
    "    #break\n",
    "\n",
    "    predfile.write(u + '-' + i + '-' + str(outOf) + ',' + str(prediction[0]*outOf) + '\\n')\n",
    "    \n",
    "predfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
