{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(In order to load the stylesheet of this notebook, execute the last code cell in this notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System for Amazon Electronics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will be working with the [Amazon dataset](http://cs-people.bu.edu/kzhao/teaching/amazon_reviews_Electronics.tar.gz). You will build a recommender system to make predictions related to reviews of Electronics products on Amazon.\n",
    "\n",
    "Your grades will be determined by your performance on the predictive tasks as well as a brief written report about the approaches you took.\n",
    "\n",
    "This assignment should be completed **individually**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train.json** 1,000,000 reviews to be used for training. It is not necessary to use all reviews for training if doing so proves too computationally intensive. The fields in this file are:\n",
    "\n",
    "* **reviewerID** The ID of the reviewer. This is a hashed user identifier from Amazon.\n",
    "\n",
    "* **asin** The ID of the item. This is a hashed product identifier from Amazon.\n",
    "\n",
    "* **overall** The rating of reviewer gave the item.\n",
    "\n",
    "* **helpful** The helpfulness votes for the review. This has 2 subfields, 'nHelpful' and 'outOf'. The latter is the total number of votes this review received. The former is the number of those that considered the review to be helpful.\n",
    "\n",
    "* **reviewText** The text of the review.\n",
    "\n",
    "* **summary** The summary of the review.\n",
    "\n",
    "* **unixReviewTime** The time of the review in seconds since 1970."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**meta.json** Contains metadata of the items:\n",
    "\n",
    "* **asin** The ID of the item.\n",
    "\n",
    "* **categories** The category labels of the item being reviewed.\n",
    "\n",
    "* **price** The price of the item.\n",
    "\n",
    "* **brand** The brand of the item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pairs_Rating.txt** The pairs (reviewerID and asin) on which you are to predict ratings.\n",
    "\n",
    "**pairs_Purchase.txt** The pairs on which you are to predict whether a user purchased an item or not.\n",
    "\n",
    "**pairs_Helpful.txt** The pairs on which you are to predict helpfulness votes. A third column in this file is the total number of votes from which you should predict how many were helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**helpful.json** The review data associated with the helpfulness prediction test set. The 'nHelpful' field has been removed from this data since that is the value you need to predict above. This data will only be of use for the helpfulness prediction task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**baseline.py** A simple baseline for each task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rating prediction** Predict people's star ratings as accurately as possible for those (reviewerID, asin) pairs in 'pairs_Rating.txt'. Accuracy will be measured in terms of the [root mean-squared error (RMSE)](http://www.kaggle.com/wiki/RootMeanSquaredError).\n",
    "\n",
    "**Purchase prediction** Predict given a (reviewerID, asin) pair from 'pairs_Purchase.txt' whether the user purchased the item (really, whether it was one of the items they reviewed). Accuracy will be measured in terms of the [categorization accuracy](http://www.kaggle.com/wiki/HammingLoss) (1 minus the Hamming loss).\n",
    "\n",
    "**Helpfulness prediction** Predic whether a user's review of an item will be considered helpful. The file 'pairs_Helpful.txt' contains (reviewerID, asin) pairs with a third column containing the number of votes the user's review of the item received. You must predict how many of them were helpful. Accuracy will be measured in terms of the total [absolute error](http://www.kaggle.com/wiki/AbsoluteError), i.e. you are penalized one according to the difference |nHelpful - prediction|, where 'nHelpful' is the number of helpful votes the review actually received, and 'prediction' is your prediction of this quantity.\n",
    "\n",
    "We set up competitions on Kaggle to keep track of your results compared to those of other members of the class. The leaderboard will show your results on half of the test data, but your ultimate score will depend on your predictions across the whole dataset.\n",
    "* Kaggle competition: [rating prediction](https://inclass.kaggle.com/c/cs591-hw3-rating-prediction3) click here to [join](https://kaggle.com/join/datascience16rating)\n",
    "* Kaggle competition: [purchase prediction](https://inclass.kaggle.com/c/cs591-hw3-purchase-prediction) click here to [join](https://kaggle.com/join/datascience16purchase)\n",
    "* Kaggle competition: [helpfulness prediction](https://inclass.kaggle.com/c/cs591-hw3-helpful-prediction) click here to [join](https://kaggle.com/join/datascience16helpful)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be graded on the following aspects.\n",
    "\n",
    "* Your written report. This should describe the approaches you took to each of the 3 tasks. To obtain good performance, you should not need to invent new approaches (though you are more than welcome to) but rather you will be graded based on your decision to apply reasonable approaches to each of the given tasks. (**10pts** for each task)\n",
    "\n",
    "* Your ability to obtain a solution which outperforms the baselines on the unseen portion of the test data. Obtaining full marks requires a solution which is substantially better (at least several percent) than baseline performance. (**10pts** for each task)\n",
    "\n",
    "* Your ranking for each of the three tasks compared to other students in the class. (**5pts** for each task)\n",
    "\n",
    "* Obtain a solution which outperforms the baselines on the seen portion of the test data (the leaderboard). \n",
    "(**5pts** for each task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple baselines have been provided for each of the 3 tasks. These are included in 'baselines.py' among the files above. These 3 baselines operate as follows:\n",
    "\n",
    "**Rating prediction** Returns the global average rating, or the user's average if you have seen them before in the training data.\n",
    "\n",
    "**Purchase prediction** Finds the most popular products that account for 50% of purchases in the training data. Return '1' whenever such a product is seen at test time, '0' otherwise.\n",
    "\n",
    "** Helpfulness prediction** Multiplies the number of votes by the global average helpfulness rate, or the user's rate if we saw this user in the training data.\n",
    "\n",
    "Running 'baseline.py' produces 3 files containing predicted outputs. Your submission files should have the same format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Citation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image-based recommendations on styles and substitutes** J. McAuley, C. Targett, J. Shi, A. van den Hengel *SIGIR*, 2015\n",
    "\n",
    "**Inferring networks of substitutable and complementary products** J. McAuley, R. Pandey, J. Leskovec *Knowledge Discovery and Data Mining*, 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOLUTION TASK 1:\n",
    "\n",
    "For rating prediction, I chose a few approaches from currently available algorithms:\n",
    "\n",
    "1. Rating = Item Average + User Bias (while refering Simon Flunk's Netflix algorithm)\n",
    " \n",
    "     Instead of taking Item average rating directly, I scaled it up using global average as well. Because if some item has a single rating, it doesn't necessarily mean it'll be the average rating. Similarly, I scaled user bias as well to get ratings with following approach:\n",
    "     \n",
    "                       Rating = scaled item average + scaled user bias\n",
    "                        Kaggle score: 1.36615 (after trying various scaling parameters)\n",
    "2. Matrix factorization:\n",
    "          Since SVD doesn't work with such sparse data set, I read about Netflix Prize algorithms from BellKor and Simon Flunk to find out UV decomposition makes this learning much easier. But the main problem here was training sufficiently large matrices. After choosing k=0 and generating (M \\times K) and (K \\times N) matrices, training each rating was taking huge time and I couldn't figure out which library could make this process faster. (I looked at xgboost, SGD Classifier but all ran for too long and I stopped the executions)\n",
    "          \n",
    "3. Regression Models:\n",
    "           In order to find rating for user-item pair, I tried to use categories from given dataset. This approach builds K models using available ratings for each category in training data. For each pair in testing data, we can then predict a value for each of these K models using regression.predict([attribute list]) and take average. But this didn't show any promising results so I didn't spend more time here.\n",
    "           I then came across DecisionTree classifiers which achieves similar goal for predicting K parameters, but using a single model. I have used this for task3 instead of spending more time here.\n",
    "           \n",
    "4. recsys library:\n",
    "            There is also a third party recommendation system library that works on top of SVD. But given this sparse data, this also gives pretty bad results on kaggle.\n",
    "            \n",
    "All the four approaches are implemented below along with in-line description for each cell:            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Averaging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "\n",
    "import time\n",
    "import sys\n",
    "from scipy.stats import logistic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 509678 43.1375191212\n"
     ]
    }
   ],
   "source": [
    "#parse data\n",
    "\n",
    "def readJson(f):\n",
    "  for l in open(f):\n",
    "    yield eval(l)\n",
    "\n",
    "now = time.time()\n",
    "usersitem = defaultdict(dict)\n",
    "mapui = defaultdict(list)\n",
    "mapiu = defaultdict(list)\n",
    "\n",
    "rate = {}\n",
    "\n",
    "for l in readJson(\"train.json\"):\n",
    "    mapui[l['reviewerID']].append(l['asin'])\n",
    "    mapiu[l['asin']].append(l['reviewerID'])\n",
    "              \n",
    "    usersitem[l['reviewerID']][l['asin']] = l['overall']\n",
    "\n",
    "print \"Done\", len(usersitem), time.time()-now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 8.6858830452 498196 42\n"
     ]
    }
   ],
   "source": [
    "#parse category fields to be used in 3) regression models\n",
    "\n",
    "now = time.time()\n",
    "itemsattr = defaultdict(list)\n",
    "\n",
    "attrset = set()\n",
    "\n",
    "for l in readJson(\"meta.json\"):\n",
    "    categ = l['categories'].translate(None,'\\'').split(\"[[\")[1].split(\"]]\")[0].split(\",\")[1:2]\n",
    "    itemsattr[l['asin']] = categ\n",
    "    attrset |= set(categ)\n",
    "    \n",
    "print \"Done\", time.time()-now, len(itemsattr), len(attrset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Car & Vehicle Electronics']\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "#check entries\n",
    "print itemsattr['03975a07fc9d5777a251e73cd7421aff026c7c5d3d58b7d66fae6d0b9d48ff7a']\n",
    "print usersitem['bc19970fff3383b2fe947cf9a3a5d7b13b6e57ef2cd53abc52bb2dfedf5fb1cd']['19e5cc4a706554d37670eabca2c19f1fc4f259361d78f0b58dafb91f3a863fc1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Now we can start populating different types of averages and see what could work best. I calculated user's average ratings, item's average ratings, user's bias values and item's bias values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509678 171185 5.04633998871\n"
     ]
    }
   ],
   "source": [
    "#populate average ratings to get global averages and per-element averages\n",
    "\n",
    "userfeature = defaultdict(dict)\n",
    "itemfeature = defaultdict(dict)\n",
    "\n",
    "avgratedict = defaultdict(list)\n",
    "useroffdict = defaultdict()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "def populateAvgDict():\n",
    "    for user in usersitem.keys():\n",
    "        for item in usersitem[user].keys():\n",
    "            #print user, usersitem[user], item, itemsattr[item]\n",
    "            avgratedict[item].append(usersitem[user][item])\n",
    "            #for feature in list(attrset):\n",
    "            for feature in itemsattr[item]:\n",
    "                #if feature in itemsattr[item]:\n",
    "                userfeature[user][feature] = usersitem[user][item]\n",
    "                itemfeature[item][feature] = usersitem[user][item]\n",
    "                \"\"\"\n",
    "                else:\n",
    "                    userfeature[user][feature] = 0.0\n",
    "                    itemfeature[item][feature] = 0.0\n",
    "                \"\"\"\n",
    "\n",
    "                \"\"\"\n",
    "                if len(userfeature) == 5:\n",
    "                    print userfeature, itemfeature\n",
    "                    sys.exit(0)\n",
    "                \"\"\"    \n",
    "    return avgratedict\n",
    "        \n",
    "avgratedict = populateAvgDict()  \n",
    "print len(userfeature), len(itemfeature), time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' Computers & Accessories': 2.0, ' Television & Video': 4.0, ' Accessories & Supplies': 2.0}\n",
      "{' Car & Vehicle Electronics': 3.0}\n"
     ]
    }
   ],
   "source": [
    "#check entries\n",
    "\n",
    "print userfeature['bc19970fff3383b2fe947cf9a3a5d7b13b6e57ef2cd53abc52bb2dfedf5fb1cd']\n",
    "print itemfeature['03975a07fc9d5777a251e73cd7421aff026c7c5d3d58b7d66fae6d0b9d48ff7a']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3837538.0 1000000 3.837538\n"
     ]
    }
   ],
   "source": [
    "#get global average of item ratings in \"globalavg\"\n",
    "\n",
    "globalsum = 0\n",
    "globalsize = 0\n",
    "\n",
    "for k,v in avgratedict.iteritems():\n",
    "    globalsum += sum(v)\n",
    "    globalsize += len(v)\n",
    "    \n",
    "globalavg = globalsum/globalsize\n",
    "\n",
    "print globalsum, globalsize, globalavg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Most of the algorithms I've seen take scaling factors (lambdas in BellKor) based on V_a and V_b, where V_a is global variance of item's ratings and V_b is variance between per item's average rating and it's actual rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2111356.09854 1538264.88976 4.25602267766\n"
     ]
    }
   ],
   "source": [
    "#calculate variance Va and Vb - this affects which parameter to choose for scaling\n",
    "\n",
    "rateVa = 0.0\n",
    "rateVb = 0.0\n",
    "\n",
    "for k,v in avgratedict.iteritems():\n",
    "    temprateVb = 0.0\n",
    "    if not len(v):\n",
    "        print k\n",
    "        break\n",
    "    curavg = 1.0*sum(v)/len(v)\n",
    "    for r in v:\n",
    "        rateVa += (globalavg-r)**2\n",
    "        rateVb += (curavg-r)**2\n",
    "\n",
    "print rateVa, rateVb, (rateVb/len(avgratedict))/(rateVa/globalsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed users' offset 509678 -7.67386154621e-11 1000000\n"
     ]
    }
   ],
   "source": [
    "#get user's bias values\n",
    "\n",
    "useroffset = defaultdict(list)\n",
    "gloffsetsum = 0.0\n",
    "gloffsetlen = 0\n",
    "for user,items in usersitem.iteritems():\n",
    "    for item, rating in items.iteritems():        \n",
    "        off = usersitem[user][item] -  sum(avgratedict[item])/len(avgratedict[item])\n",
    "        useroffset[user].append(off)\n",
    "        gloffsetsum += off\n",
    "        gloffsetlen+=1\n",
    "        \n",
    "gloffsetavg = gloffsetsum/gloffsetlen\n",
    "print \"Computed users' offset\", len(useroffset), gloffsetsum, gloffsetlen\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed items' offset 171185 233142.395601 1000000\n"
     ]
    }
   ],
   "source": [
    "#get item's bias values - NOT chosen for final prediction routine\n",
    "\n",
    "itemoffset = defaultdict(list)\n",
    "itemgloffsetsum = 0.0\n",
    "itemgloffsetlen = 0\n",
    "for items,ratelist in avgratedict.iteritems():\n",
    "    for rating in ratelist:\n",
    "        off = rating - sum(avgratedict[item])/len(avgratedict[item])\n",
    "        itemoffset[items].append(off)\n",
    "        \n",
    "        #off = usersitem[user][item] -  sum(avgratedict[item])/len(avgratedict[item])\n",
    "        #useroffset[user].append(off)\n",
    "        \n",
    "        itemgloffsetsum += off\n",
    "        itemgloffsetlen+=1\n",
    "        \n",
    "itemgloffsetavg = itemgloffsetsum/itemgloffsetlen\n",
    "print \"Computed items' offset\", len(itemoffset), itemgloffsetsum, itemgloffsetlen\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1538264.88976 591856.023241 0.549994943614\n"
     ]
    }
   ],
   "source": [
    "#calculate variance Va and Vb for offset - reference for scaling parameters\n",
    "\n",
    "offVa = 0.0\n",
    "offVb = 0.0\n",
    "\n",
    "for user,items in usersitem.iteritems():\n",
    "    userOff = 0.0\n",
    "    userOffAvg = sum(useroffset[user] )/len(useroffset[user])\n",
    "    \n",
    "    for item, rating in items.iteritems():        \n",
    "        curOff = usersitem[user][item] -  sum(avgratedict[item])/len(avgratedict[item])\n",
    "        offVa += (gloffsetavg - curOff)**2\n",
    "        userOff += (userOffAvg - curOff)**2\n",
    "    offVb += userOff\n",
    "        \n",
    "\n",
    "print offVa, offVb, (offVb/len(useroffset))/(rateVa/gloffsetlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Instead of reading test data again and again, store it in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readJson(f):\n",
    "  for l in open(f):\n",
    "    yield eval(l)\n",
    "\n",
    "def parseData(fname):\n",
    "  for l in urllib.urlopen(fname):\n",
    "    yield eval(l)\n",
    "    \n",
    "allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "data = []\n",
    "\n",
    "for l in readJson(\"train.json\"):\n",
    "    data.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1233948.17301\n"
     ]
    }
   ],
   "source": [
    "#Train average ratings and user bias values to get better predictions\n",
    "\n",
    "itemavgdict = defaultdict()\n",
    "userbiasdict = defaultdict()\n",
    "itembiasdict = defaultdict()\n",
    "\n",
    "def SVDBaseTrain(userid, itemid, actual, k1=6.5, k2=3.5):\n",
    "    \"\"\"\n",
    "    Take user-item pair and it's actual rating. Compare with the predicted rating and adjust \n",
    "    average rating and bias ratings\n",
    "    \"\"\"\n",
    "    ret = 0.0\n",
    "    try:\n",
    "        rateavg = avgratedict[itemid]\n",
    "    except KeyError:\n",
    "        rateavg = []\n",
    "    try:\n",
    "        offset = useroffset[userid] \n",
    "    except KeyError:\n",
    "        offset = []\n",
    "        \n",
    "    try:\n",
    "        itemoff = itemoffset[itemid]\n",
    "    except KeyError:\n",
    "        itemoff = []\n",
    "\n",
    "    itemavg = 0.0\n",
    "    offsetavg = 0.0\n",
    "    itembiasavg = 0.0\n",
    "    \n",
    "    for i in xrange(5):\n",
    "        \n",
    "        \"\"\"\n",
    "        Scaling logic:\n",
    "        value = (K* value's global avg + global sum)/(K + global length)\n",
    "        This K depends on V_a and V_b of value and I found 6.5 and 3.5 to be sufficiently good\n",
    "        \"\"\"\n",
    "        newitemavg = (globalavg*k1 + sum(rateavg))/(k1 + len(rateavg))\n",
    "        newoffsetavg = (gloffsetavg*k2+sum(offset))/(k2+len(offset))\n",
    "        newitemoff = (itemgloffsetavg*k2+sum(itemoff))/(k2+len(itemoff))\n",
    "        \n",
    "        trainpredict = newitemavg + newoffsetavg\n",
    "        err = actual- trainpredict\n",
    "        #if err < 0.001:\n",
    "            #break\n",
    "        itemavg = newitemavg + 0.001*(err) #+ 0.0001*(err**2)\n",
    "        offsetavg = newoffsetavg + 0.001*(err) #+ 0.0001*(err**2)\n",
    "             \n",
    "        itembiasavg = newitemoff + 0.0002*(err)\n",
    "        \n",
    "    itemavgdict[itemid] = itemavg\n",
    "    userbiasdict[userid] = offsetavg\n",
    "    itembiasdict[itemid] = itembiasavg\n",
    "    \n",
    "    ret =  min(4.6, max(1.6,itemavg+offsetavg))\n",
    "    return ret\n",
    "\n",
    "\n",
    "mse = 0.0\n",
    "for test in data:\n",
    "    actual = test['overall']\n",
    "    predict = SVDBaseTrain(test['reviewerID'], test['asin'], actual)\n",
    "    \n",
    "    mse += (predict-actual)**2\n",
    "    #break\n",
    "print mse\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Get predictions based on trained data and write to file (0.4 sec for 100,000 pairs - very fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0.432390213013\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def SVDBase(userid, itemid, k1=6.5, k2=3.5):\n",
    "    \"\"\"\n",
    "    This is essentially same logic as used in training.    \n",
    "    \"\"\"\n",
    "    ret = 0.0\n",
    "    try:\n",
    "        itemavg = itemavgdict[itemid]\n",
    "    except:\n",
    "    \n",
    "        try:\n",
    "            rateavg = avgratedict[itemid]\n",
    "        except KeyError:\n",
    "            rateavg = []\n",
    "        itemavg = (globalavg*k1 + sum(rateavg))/(k1 + len(rateavg))\n",
    "    try:\n",
    "        offsetavg = userbiasdict[userid]\n",
    "    except:\n",
    "        try:\n",
    "            offset = useroffset[userid] \n",
    "        except KeyError:\n",
    "            offset = []\n",
    "        offsetavg = (gloffsetavg*k2+sum(offset))/(k2+len(offset))\n",
    "            \n",
    "    try:\n",
    "        itembias = itembiasdict[itemid]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            itemoff = itemoffset[itemid]\n",
    "        except KeyError:\n",
    "            itemoff = []\n",
    "        itembias = (itemgloffsetavg*k2+sum(itemoff))/(k2+len(itemoff))*0.5\n",
    "        \n",
    "        \n",
    "          \n",
    "    ret =  min(4.6, max(1.6,itemavg+offsetavg))\n",
    "     \n",
    "    return ret\n",
    "\n",
    "\n",
    "ratefile = open(\"biasTrain_Rating.txt\",\"w\")\n",
    "#intratefile = open(\"INTpreSVD_Rating.txt\",\"w\")\n",
    "ratefile.write(\"reviewerID-asin,prediction\\n\")\n",
    "#intratefile.write(\"reviewerID-asin,prediction\\n\")\n",
    "start = time.time()\n",
    "\n",
    "reqUser = defaultdict(dict)\n",
    "reqItem = defaultdict(dict)\n",
    "reqAttr = set()\n",
    "\n",
    "with open(\"pairs_Rating.txt\") as prate:\n",
    "    for pair in prate:\n",
    "        #print pair\n",
    "        if pair.startswith(\"reviewer\"):\n",
    "            continue\n",
    "        \n",
    "        userid, itemid = pair.split(\"-\")\n",
    "        itemid = itemid[:-1]\n",
    "        basepredict = SVDBase(userid,itemid)                \n",
    "                \n",
    "        ratefile.write(\"%s-%s,%f\\n\" % (userid, itemid, basepredict))\n",
    "        #intratefile.write(\"%s-%s,%d\\n\" % (userid, itemid, int(round(basepredict))))\n",
    "        #sys.exit(0)\n",
    "ratefile.close()\n",
    "#intratefile.close()\n",
    "        \n",
    "print \"Done\", time.time()-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Following cell is just a backup of my previous attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Done 0.76405620575 88257 47289 27\n"
     ]
    }
   ],
   "source": [
    "#backup\n",
    "\n",
    "import math\n",
    "#head start before SVD\n",
    "\n",
    "\n",
    "def SVDBase(userid, itemid, k1=4, k2=4):\n",
    "    ret = 0.0\n",
    "    try:\n",
    "        rateavg = avgratedict[itemid]\n",
    "    except KeyError:\n",
    "        rateavg = []\n",
    "    try:\n",
    "        offset = useroffset[userid] \n",
    "    except KeyError:\n",
    "        offset = []\n",
    "        \n",
    "    #if not len(rateavg) or not len(offset):\n",
    "        #print userid, itemid\n",
    "    #if len(rateavg):\n",
    "    itemavg = (globalavg*k1 + sum(rateavg))/(k1 + len(rateavg))\n",
    "    #else:\n",
    "        #itemavg = globalavg\n",
    "    #if len(offset):\n",
    "    offsetavg = (gloffsetavg*k2+sum(offset))/(k2+len(offset))\n",
    "    #else:\n",
    "        #offsetavg = 0.0\n",
    "\n",
    "    ret =  min(5.0, max(0.5,itemavg+offsetavg))\n",
    "\n",
    "    #except KeyError:\n",
    "        #ret = min(5.0, max(0.5, globalavg))\n",
    "        \n",
    "    return ret\n",
    "\n",
    "\n",
    "ratefile = open(\"preSVDpred_Rating.txt\",\"w\")\n",
    "#intratefile = open(\"INTpreSVD_Rating.txt\",\"w\")\n",
    "ratefile.write(\"reviewerID-asin,prediction\\n\")\n",
    "#intratefile.write(\"reviewerID-asin,prediction\\n\")\n",
    "start = time.time()\n",
    "\n",
    "reqUser = defaultdict(dict)\n",
    "reqItem = defaultdict(dict)\n",
    "reqAttr = set()\n",
    "\n",
    "with open(\"pairs_Rating.txt\") as prate:\n",
    "    for pair in prate:\n",
    "        #print pair\n",
    "        if pair.startswith(\"reviewer\"):\n",
    "            continue\n",
    "        \n",
    "        userid, itemid = pair.split(\"-\")\n",
    "        itemid = itemid[:-1]\n",
    "        basepredict = SVDBase(userid,itemid)                \n",
    "        \n",
    "        reqUser[userid][itemid] = basepredict\n",
    "        reqItem[itemid][userid] = basepredict\n",
    "        reqAttr |= set(itemsattr[itemid])\n",
    "        usersitem[userid][itemid] = basepredict\n",
    "        ratefile.write(\"%s-%s,%f\\n\" % (userid, itemid, basepredict))\n",
    "        #intratefile.write(\"%s-%s,%d\\n\" % (userid, itemid, int(round(basepredict))))\n",
    "        #sys.exit(0)\n",
    "ratefile.close()\n",
    "#intratefile.close()\n",
    "        \n",
    "print \"Done\", time.time()-start, len(reqUser), len(reqItem), len(reqAttr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. UV Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    This is the second approach I tried by creating two matrices and training all features. But it's very slow and partial training doesn't give any good results\n",
    "    \n",
    "    ## EXECUTE PREVIOUS CELL BEFORE PROCEEDING ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88257 10 47289 10\n",
      "(88257, 10) (47289, 10) [ 0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1] [ 0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1]\n",
      "Done 0.0604639053345\n"
     ]
    }
   ],
   "source": [
    "## DATA REDUCTION\n",
    "attrlist = sorted(reqAttr)\n",
    "userlist = list(reqUser.keys())\n",
    "itemlist = list(reqItem.keys())\n",
    "\n",
    "#r = [0.1 for _ in xrange(len(attrlist))]\n",
    "r = [0.1 for _ in xrange(10)]\n",
    "userfeat = [r for _ in xrange(len(reqUser)) ]\n",
    "itemfeat = [r for _ in xrange(len(reqItem)) ]\n",
    "\n",
    "print len(userfeat), len(userfeat[0]), len(itemfeat), len(itemfeat[0])\n",
    "\n",
    "start = time.time()\n",
    "#print list(reqUser.keys()).index(\"f0ce42c52f549e542b28cb6351b93814be2c571809bca8eab2e191e601ada746\")\n",
    "U = np.array(userfeat)\n",
    "V = np.array(itemfeat)\n",
    "\n",
    "print U.shape, V.shape, U[0], V[0]\n",
    "        \n",
    "print \"Done\", time.time()-start            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Train each feature for each user and each item : huge matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-b645ac590b1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m \u001b[0mnU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrainMatrices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mnU\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnV\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-b645ac590b1f>\u001b[0m in \u001b[0;36mTrainMatrices\u001b[1;34m(P, Q, K, steps, alpha, beta)\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmapui\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muserlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0munum\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                     \u001b[0minum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitemlist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                     \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training\n",
    "\n",
    "def predictRatingBase(user, item, k1=5, k2=5):\n",
    "    ret = 0.0\n",
    "    try:\n",
    "        itemavg = itemavgdict[itemid]\n",
    "    except:\n",
    "    \n",
    "        try:\n",
    "            rateavg = avgratedict[itemid]\n",
    "        except KeyError:\n",
    "            rateavg = []\n",
    "        itemavg = (globalavg*k1 + sum(rateavg))/(k1 + len(rateavg))\n",
    "    try:\n",
    "        offsetavg = userbiasdict[userid]\n",
    "    except:\n",
    "        try:\n",
    "            offset = useroffset[userid] \n",
    "        except KeyError:\n",
    "            offset = []\n",
    "        \n",
    "        offsetavg = (gloffsetavg*k2+sum(offset))/(k2+len(offset))\n",
    "          \n",
    "    ret =  min(5.0, max(0.5,itemavg+offsetavg))\n",
    "     \n",
    "    return ret\n",
    "\n",
    "#def predictRating\n",
    "\n",
    "def TrainMatrices(P, Q, K, steps=100, alpha=0.0002, beta=0.02):\n",
    "    Q = Q.T\n",
    "    for step in xrange(steps):\n",
    "        for unum in xrange(len(userlist)):\n",
    "            \n",
    "            for item in mapui[userlist[unum]]:\n",
    "                try:\n",
    "                    inum = itemlist.index(item)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "            \n",
    "                try:\n",
    "                    rate = usersitem[userlist[unum]][itemlist[inum]]\n",
    "                    eij = rate - np.dot(P[unum,:],Q[:,inum])\n",
    "                    for k in xrange(K):\n",
    "                        P[unum][k] = P[unum][k] + alpha * (2 * eij * Q[k][inum] - beta * P[unum][k])\n",
    "                        Q[k][inum] = Q[k][inum] + alpha * (2 * eij * P[unum][k] - beta * Q[k][inum])\n",
    "                    #print \"update\", unum, P[unum][k], Q[k][inum]\n",
    "                    #break\n",
    "                except KeyError:\n",
    "                    continue\n",
    "                \n",
    "        #eR = np.dot(P,Q)\n",
    "        e = 0\n",
    "        for unum in xrange(len(userlist)):            \n",
    "            for item in mapui[userlist[unum]]:\n",
    "                try:\n",
    "                    inum = itemlist.index(item)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                try:\n",
    "                    rate = usersitem[userlist[unum]][attrlist[inum]]\n",
    "                \n",
    "                    e = e + pow(rate - numpy.dot(P[unum,:],Q[:,inum]), 2)\n",
    "                    for k in xrange(K):\n",
    "                        e = e + (beta/2) * ( pow(P[unum][k],2) + pow(Q[k][inum],2))\n",
    "                except KeyError:\n",
    "                    continue\n",
    "            if e < 0.001:\n",
    "                break\n",
    "            \n",
    "    return P, Q.T\n",
    "\n",
    "start = time.time()\n",
    "nU, nV = TrainMatrices(U, V, 5)\n",
    "print nU[0], nV[0]\n",
    "  \n",
    "print time.time() - start\n",
    "\n",
    "np.savetxt('newUser.out', nU, delimiter=',')\n",
    "np.savetxt('newItem.out', nV, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-3438b4371b79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0muserid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitemid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpair\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mitemid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitemid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mbasepredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictRating\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muserlist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muserid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mitemlist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitemid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mratefile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s-%s,%f\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0muserid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitemid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasepredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## SVD (Training too sloooow)\n",
    "start = time.time()\n",
    "def predictRating(user,item):\n",
    "    ret = 0.0\n",
    "    for i in xrange(len(attrlist)):\n",
    "        ret += U[user][i]*V[item][i]\n",
    "        ret = min(5.0, max(0.0, ret))\n",
    "    #print ret,\n",
    "    return ret\n",
    "        \n",
    "def train(f, user, item, rating, lrate=0.002, K=0.01):\n",
    "    err = lrate*(rating - predictRating(user,item))\n",
    "    uv = U[user][f]\n",
    "    \n",
    "    U[user][f] += lrate*(err*V[item][f] - K*U[user][f])\n",
    "    V[item][f] += lrate*(err*U[user][f] - K*V[item][f])   \n",
    "\"\"\"\n",
    "for u in xrange(10):\n",
    "    for i in xrange(len(itemlist)):\n",
    "        for f in xrange(len(attrlist)):\n",
    "            try:\n",
    "                rating = usersitem[userlist[u]][itemlist[i]]\n",
    "            except KeyError:\n",
    "                continue\n",
    "            train(f,u,i,rating)\n",
    "\"\"\"   \n",
    "ratefile = open(\"pseudoSVD_Rating.txt\",\"w\")\n",
    "ratefile.write(\"reviewerID-asin,prediction\\n\")\n",
    "\n",
    "with open(\"pairs_Rating.txt\") as prate:\n",
    "    for pair in prate:\n",
    "        #print pair\n",
    "        if pair.startswith(\"reviewer\"):\n",
    "            continue\n",
    "        \n",
    "        userid, itemid = pair.split(\"-\")\n",
    "        itemid = itemid[:-1]\n",
    "        basepredict = predictRating(userlist.index(userid),itemlist.index(itemid))                \n",
    "                \n",
    "        ratefile.write(\"%s-%s,%f\\n\" % (userid, itemid, basepredict))\n",
    "        \n",
    "ratefile.close()\n",
    "            \n",
    "print \"Time\", time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3. Recsys library SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratingfile = \"myrating.dat\"\n",
    "rf = open(ratingfile,\"w\")\n",
    "for u,v in usersitem.iteritems():\n",
    "    for i,r in v.iteritems():\n",
    "        rf.write(\"%s::%s::%s\\n\" %(u,i,r))\n",
    "rf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded 15.504899025\n",
      "Computed 32.8592751026\n"
     ]
    }
   ],
   "source": [
    "from recsys.algorithm.factorize import SVD\n",
    "from recsys.datamodel.data import Data\n",
    "\n",
    "svd = SVD()\n",
    "data = Data()\n",
    "\n",
    "start = time.time()\n",
    "data.load(ratingfile, sep='::', format={'col':0, 'row':1, 'value':2, 'ids':str})\n",
    "print \"Data loaded\", time.time()-start\n",
    "K=100\n",
    "svd.set_data(data)\n",
    "svd.compute(k=K, min_values=5, pre_normalize=None, mean_center=True, post_normalize=True, savefile='/tmp/itemsSVD')\n",
    "print \"Computed\", time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f0ce42c52f549e542b28cb6351b93814be2c571809bca8eab2e191e601ada746 6116d31a297ceb0f8f69f6f71e924e47136fc70c6f5bf75c7af0363663760159 2.00591303169\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def SVDBase(userid, itemid):\n",
    "    ret = 0.0\n",
    "    try:\n",
    "        rateavg = avgratedict[itemid]\n",
    "        offset = useroffset[userid] \n",
    "        #if not len(rateavg) or not len(offset):\n",
    "            #print userid, itemid\n",
    "        if len(rateavg):\n",
    "            itemavg = (globalavg*25 + sum(rateavg))/(25 + len(rateavg))\n",
    "        else:\n",
    "            itemavg = globalavg\n",
    "        if len(offset):\n",
    "            offsetavg = sum(offset)/len(offset)\n",
    "        else:\n",
    "            offsetavg = 0.0\n",
    "\n",
    "        ret =  min(5.0, max(0.5,itemavg+offsetavg))\n",
    "\n",
    "    except KeyError:\n",
    "        ret = min(5.0, max(0.5, globalavg))\n",
    "        \n",
    "    return ret\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ratefile = open(\"recsys_SVD.txt\",\"w\")\n",
    "ratefile.write(\"reviewerID-asin,prediction\\n\")\n",
    "\n",
    "with open(\"pairs_Rating.txt\") as prate:\n",
    "    for pair in prate:\n",
    "        #print pair\n",
    "        if pair.startswith(\"reviewer\"):\n",
    "            continue\n",
    "        \n",
    "        userid, itemid = pair.split(\"-\")\n",
    "        itemid = itemid[:-1]\n",
    "        try:\n",
    "            pred_rating = svd.predict(itemid, userid)\n",
    "        except KeyError:\n",
    "            pred_rating = SVDBase(userid, itemid)\n",
    "                \n",
    "        print userid, itemid, pred_rating\n",
    "        ratefile.write(\"%s-%s,%f\\n\" % (userid, itemid, pred_rating))\n",
    "        break\n",
    "ratefile.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. CLF and Logical Regression for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Homework 3\n",
    "\n",
    "import numpy\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn import linear_model, datasets\n",
    "from __future__ import division\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "def readJson(f):\n",
    "  for l in open(f):\n",
    "    yield eval(l)\n",
    "\n",
    "def parseData(fname):\n",
    "  for l in urllib.urlopen(fname):\n",
    "    yield eval(l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    }
   ],
   "source": [
    "itemset = set([])\n",
    "userset = set([])\n",
    "\n",
    "training = []\n",
    "train = data\n",
    "\n",
    "\n",
    "ratingList = []\n",
    "userRateList = defaultdict(list)\n",
    "data = []\n",
    "\n",
    "for l in readJson(\"train.json\"):\n",
    "    data.append(l)\n",
    "\n",
    "\n",
    "for l in train:\n",
    "    training.append((l['reviewerID']+\"-\"+l['asin'], l['overall']))\n",
    "    userset.add(l['reviewerID'])\n",
    "    itemset.add(l['asin'])\n",
    "\n",
    "print len(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Create X,y for regression model fit() and then predict using test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "Done 88.8999919891\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reqAttr = set()\n",
    "\n",
    "with open(\"pairs_Rating.txt\") as prate:\n",
    "    for pair in prate:\n",
    "        if pair.startswith(\"reviewer\"):\n",
    "            continue\n",
    "        \n",
    "        userid, itemid = pair.split(\"-\")\n",
    "        itemid = itemid[:-1]\n",
    "\n",
    "        reqAttr |= set(itemsattr[itemid])\n",
    "\n",
    "attrlist = sorted(reqAttr)\n",
    "print len(attrlist)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "useritemX = []\n",
    "\n",
    "attrlistrate = defaultdict(list)\n",
    "uifeatlist = {}\n",
    "iratingY = []\n",
    "\n",
    "for l in data:\n",
    "    iratingY.append(int(l['overall']))\n",
    "    \n",
    "    uAttr = [[0] for _ in xrange(len(attrlist))]\n",
    "    iAttr = [[0] for _ in xrange(len(attrlist))]\n",
    "    for f in xrange(len(attrlist)):            \n",
    "        try:\n",
    "            uAttr[f] = int(userfeature[l['reviewerID']][attrlist[f]])\n",
    "        except KeyError:\n",
    "            uAttr[f] = 0    \n",
    "        try:\n",
    "            iAttr[f] = int(itemfeature[l['asin']][attrlist[f]])\n",
    "        except KeyError:\n",
    "            iAttr[f] = 0\n",
    "\n",
    "    useritemX.append(iAttr)\n",
    "    uifeatlist[l['asin']] = \"\".join(map(str, uAttr+iAttr))\n",
    "    attrlistrate[\"\".join(map(str, uAttr+iAttr))].append(int(l['overall']))\n",
    "print \"Done\", time.time()-start    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2.67341303825\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "iratingY = []\n",
    "\n",
    "for l in train:\n",
    "    \n",
    "    try:\n",
    "        #featvec = attrlistrate[uifeatlist[l['reviewerID']+l['asin']]]\n",
    "        featvec = attrlistrate[uifeatlist[l['reviewerID']+l['asin']]]\n",
    "    except KeyError:\n",
    "        featvec = []\n",
    "    pairsum = (globalavg*5 + sum(featvec))\n",
    "    pairlen = (5+len(featvec))\n",
    "    iratingY.append(int(round(10.0*pairsum/pairlen)))\n",
    "    #break\n",
    "print \"Done\", time.time()-start    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000 [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 1000000\n",
      "Done 4.51120710373\n"
     ]
    }
   ],
   "source": [
    "print len(useritemX), useritemX[0], len(iratingY)\n",
    "print \"Done\", time.time()-start    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 27) (1000000,)\n",
      "Done 9.97780799866 38 [0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[0 2 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n",
      "[38 38 38 ..., 38 38 38]\n"
     ]
    }
   ],
   "source": [
    "           \n",
    "U = np.array(useritemX)\n",
    "V = np.array(iratingY)\n",
    "\n",
    "print U.shape, V.shape\n",
    "print \"Done\", time.time()-start, V[0], U[0]\n",
    "print U\n",
    "print V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bc19970fff3383b2fe947cf9a3a5d7b13b6e57ef2cd53abc52bb2dfedf5fb1cd-a6ed402934e3c1138111dce09256538afb04c566edf37c16b9ba099d23afb764', 2.0)\n",
      "2.0 [2.0, -0.354421768707483]\n"
     ]
    }
   ],
   "source": [
    "#logical reg vectors create X and y\n",
    "\n",
    "X=[]\n",
    "y=[]\n",
    "print training[0]\n",
    "for (ui, rating) in training:\n",
    "    \n",
    "    u,i = ui.strip().split('-')\n",
    "\n",
    "    avgoff = sum(useroffset[u])/len(useroffset[u])\n",
    "    avgrate = sum(avgratedict[i])/len(avgratedict[i])\n",
    "    elem=[avgrate,avgoff]\n",
    "    \n",
    "    y.append(rating)\n",
    "    X.append(elem)\n",
    "\n",
    "print y[0], X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.03834256 -2.11525601]\n",
      " [-0.71004675 -0.75658956]\n",
      " [-0.35640411 -0.35394266]\n",
      " [ 0.06877642  0.11963284]\n",
      " [ 2.30445359  2.41390122]]\n"
     ]
    }
   ],
   "source": [
    "#logical reg fit()\n",
    "logreg = linear_model.LogisticRegression()\n",
    "logreg.fit(X, y)\n",
    "print logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of class labels must be greater than one.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-1de218872eba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGDClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/sahil/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    543\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m                          sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sahil/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m         self._partial_fit(X, y, alpha, C, loss, learning_rate, self.n_iter,\n\u001b[1;32m--> 415\u001b[1;33m                           classes, sample_weight, coef_init, intercept_init)\n\u001b[0m\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sahil/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.pyc\u001b[0m in \u001b[0;36m_partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, n_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m    377\u001b[0m                              sample_weight=sample_weight, n_iter=n_iter)\n\u001b[0;32m    378\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m             raise ValueError(\"The number of class labels must be \"\n\u001b[0m\u001b[0;32m    380\u001b[0m                              \"greater than one.\")\n\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The number of class labels must be greater than one."
     ]
    }
   ],
   "source": [
    "#takes too much time - SGD\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(U, V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predict using regression \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "clfpredictions = open(\"SGD_Rating.txt\", 'w')\n",
    "clfpredictions.write(\"reviewerID-asin,prediction\\n\")\n",
    "\n",
    "for l in open(\"pairs_Rating.txt\"):\n",
    "    if l.startswith(\"reviewer\"):\n",
    "        #header\n",
    "        continue\n",
    "    userid,itemid = l[:-1].strip().split('-')\n",
    "    \n",
    "    uAttr = [[0] for _ in xrange(len(attrlist))]\n",
    "    iAttr = [[0] for _ in xrange(len(attrlist))]\n",
    "    for f in xrange(len(attrlist)):            \n",
    "        try:\n",
    "            uAttr[f] = userfeature[userid][attrlist[f]]\n",
    "        except KeyError:\n",
    "            uAttr[f] = 0    \n",
    "        try:\n",
    "            iAttr[f] = userfeature[itemid][attrlist[f]]\n",
    "        except KeyError:\n",
    "            iAttr[f] = 0\n",
    "                        \n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "    sgdpred = clf.predict([uAttr+iAttr])[0]\n",
    "    \n",
    "    offset = useroffset[userid] \n",
    "    if len(offset):\n",
    "        offsetavg = sum(offset)/len(offset)\n",
    "    else:\n",
    "        offsetavg = 0.0\n",
    "        \n",
    "    sgdpred = min(5.0, max(0.5,sgdpred/10+offsetavg))\n",
    "    #print sgdpred, sgdpred/10+offsetavg\n",
    "    #break\n",
    "\n",
    "    clfpredictions.write(userid + '-' + itemid + \",\"+str(sgdpred)+\"\\n\")\n",
    "\n",
    "    #break\n",
    "clfpredictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predict using regression \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "predictions = open(\"logreg_Rating.txt\", 'w')\n",
    "predictions.write(\"reviewerID-asin,prediction\\n\")\n",
    "clfpredictions = open(\"SGD_Rating.txt\", 'w')\n",
    "clfpredictions.write(\"reviewerID-asin,prediction\\n\")\n",
    "\n",
    "for l in open(\"pairs_Rating.txt\"):\n",
    "    if l.startswith(\"reviewer\"):\n",
    "        #header\n",
    "        continue\n",
    "    userid,itemid = l[:-1].strip().split('-')\n",
    "    \n",
    "    rateavg = avgratedict[itemid]\n",
    "    offset = useroffset[userid] \n",
    "    #if not len(rateavg) or not len(offset):\n",
    "        #print userid, itemid\n",
    "    if len(rateavg):\n",
    "        itemavg = (globalavg*25 + sum(rateavg))/(25 + len(rateavg))\n",
    "    else:\n",
    "        itemavg = globalavg\n",
    "    if len(offset):\n",
    "        offsetavg = sum(offset)/len(offset)\n",
    "    else:\n",
    "        offsetavg = 0.0\n",
    "        \n",
    "            \n",
    "    #print u,i, itemsRank[0], usersRank[0]\n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "    pred = logreg.predict([itemavg,offsetavg])[0]\n",
    "    sgdpred = clf.predict([itemavg,offsetavg])[0]\n",
    "    #print sgdpred\n",
    "    \n",
    "    sgdpred = clf.predict_proba([itemavg,offsetavg])[0]\n",
    "    print sgdpred\n",
    "    break\n",
    "    #sys.exit(0)\n",
    "    #print pred\n",
    "    \n",
    "    #sys.exit(0)\n",
    "    #if (logreg.predict([itemsRank,usersRank])==[0]):\n",
    "    predictions.write(userid + '-' + itemid + \",\"+str(pred)+\"\\n\")\n",
    "    clfpredictions.write(userid + '-' + itemid + \",\"+str(sgdpred)+\"\\n\")\n",
    "    #else:\n",
    "        #predictions.write(u + '-' + i + \",1\\n\")\n",
    "    #break\n",
    "predictions.close()\n",
    "clfpredictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code for setting the style of the notebook\n",
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"../theme/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
